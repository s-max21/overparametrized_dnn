{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\max-s\\Desktop\\Uni\\Master\\Masterthesis\\Code\\git\\overparametrized_dnn\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Working Directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data_generator import get_data, preprocess\n",
    "from src.my_dnn import create_dnn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras_tuner as kt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n",
      "2.15.0\n",
      "1.4.7\n",
      "1.26.4\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "print(kt.__version__)\n",
    "print(np.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_func(x):\n",
    "    return np.exp(np.linalg.norm(x, axis=1))\n",
    "\n",
    "input_dim = 7\n",
    "\n",
    "x, y = get_data(regression_func, x_dim=input_dim, num_samples=100, sigma=0.05)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "train_data = preprocess(x_train, y_train, batch_size=80, training=True)\n",
    "val_data = preprocess(x_val, y_val, batch_size=20, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    hp_units = hp.Int(\"units\", min_value=10, max_value=40, step=10)\n",
    "    hp_layers = hp.Int(\"layers\", min_value=5, max_value=20, step=5)\n",
    "    hp_nets = hp.Int(\"networks\", min_value=80, max_value=6 * 80, step=80)\n",
    "    hp_beta = hp.Float('beta', min_value=20, max_value=80)\n",
    "    hp_gamma = hp.Float('gamma', min_value=30, max_value=80)\n",
    "    hp_learning_rate = hp.Float(\n",
    "        \"learning_rate\", min_value=np.exp(-16), max_value=np.exp(-14), sampling=\"log\"\n",
    "    )\n",
    "\n",
    "    # Hier nutzen Sie Ihre angepasste `create_dnn` Funktion mit den hp-Argumenten\n",
    "    model = create_dnn(\n",
    "        train_shape=x_train.shape,  # Beispielwerte\n",
    "        num_networks=hp_nets,\n",
    "        num_layers=hp_layers,\n",
    "        num_neurons=hp_units,\n",
    "        beta=hp_beta,\n",
    "        gamma=hp_gamma,\n",
    "        delta=1,\n",
    "    )\n",
    "\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=hp_learning_rate)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"mean_squared_error\", metrics=[\"mean_squared_error\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    model_builder,\n",
    "    objective='val_loss',\n",
    "    max_trials=20,\n",
    "    executions_per_trial=2,\n",
    "    directory='my_dir',\n",
    "    project_name='rs_tuning'\n",
    ")\n",
    "\n",
    "# Starten des Tuning-Prozesses\n",
    "tuner.search(x_train, y_train, epochs=250, validation_data=(x_val, y_val))\n",
    "\n",
    "# Abrufen der besten Hyperparameter\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Die besten Hyperparameter sind:\n",
      "- Anzahl der Netzwerke: 160\n",
      "- Anzahl der Schichten: 10\n",
      "- Anzahl der Neuronen: 20\n",
      "- Delta: 4.156935364128902e-07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Die besten Hyperparameter sind:\n",
    "- Anzahl der Netzwerke: {best_hps.get('networks')}\n",
    "- Anzahl der Schichten: {best_hps.get('layers')}\n",
    "- Anzahl der Neuronen: {best_hps.get('units')}\n",
    "- Delta: {best_hps.get('learning_rate')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_dnn(model, train_data, test_data, epochs=75):\n",
    "    \"\"\"\n",
    "    Trains the model on the given data and evaluates its performance.\n",
    "    \"\"\"\n",
    "    model.fit(train_data, epochs=epochs, verbose=0)\n",
    "    mse, mae = model.evaluate(test_data, verbose=0)\n",
    "    return mse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:174: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\max-s\\Desktop\\Uni\\Master\\Masterthesis\\Code\\git\\overparametrized_dnn\\src\\my_dnn.py\", line 176, in train_step  *\n        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 269, in apply_gradients  **\n        self.apply(grads, trainable_variables)\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 334, in apply\n        variable.assign(variable.constraint(variable))\n    File \"c:\\Users\\max-s\\Desktop\\Uni\\Master\\Masterthesis\\Code\\git\\overparametrized_dnn\\src\\my_dnn.py\", line 65, in __call__\n        return self.apply_l1_projection(w)\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_type.py\", line 583, in canonicalize_to_monomorphic\n        _make_validated_mono_param(name, arg, poly_parameter.kind,\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_type.py\", line 522, in _make_validated_mono_param\n        mono_type = trace_type.from_value(value, type_context)\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\tensorflow\\core\\function\\trace_type\\trace_type_builder.py\", line 185, in from_value\n        ndarray = value.__array__()\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\backend\\common\\variables.py\", line 198, in __array__\n        return np.asarray(self.value.__array__(dtype))\n\n    NotImplementedError: numpy() is only available when eager execution is enabled.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 30\u001b[0m\n\u001b[0;32m     25\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m15\u001b[39m))\n\u001b[0;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     28\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     29\u001b[0m )\n\u001b[1;32m---> 30\u001b[0m mse, mae \u001b[38;5;241m=\u001b[39m train_and_evaluate_dnn(model, train_data, test_data, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n\u001b[0;32m     31\u001b[0m mses\u001b[38;5;241m.\u001b[39mappend(mse)\n\u001b[0;32m     32\u001b[0m maes\u001b[38;5;241m.\u001b[39mappend(mae)\n",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m, in \u001b[0;36mtrain_and_evaluate_dnn\u001b[1;34m(model, train_data, test_data, epochs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_and_evaluate_dnn\u001b[39m(model, train_data, test_data, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m75\u001b[39m):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    Trains the model on the given data and evaluates its performance.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(train_data, epochs\u001b[38;5;241m=\u001b[39mepochs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      6\u001b[0m     mse, mae \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_data, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mse, mae\n",
      "File \u001b[1;32mc:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileegyz1r8b.py:28\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     26\u001b[0m trainable_vars \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mtrainable_variables\n\u001b[0;32m     27\u001b[0m gradients \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tape)\u001b[38;5;241m.\u001b[39mgradient, (ag__\u001b[38;5;241m.\u001b[39mld(loss), ag__\u001b[38;5;241m.\u001b[39mld(trainable_vars)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m---> 28\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mapply_gradients, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mzip\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(gradients), ag__\u001b[38;5;241m.\u001b[39mld(trainable_vars)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     29\u001b[0m current_weights \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mconcat, ([ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mreshape, (ag__\u001b[38;5;241m.\u001b[39mld(w), [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]), \u001b[38;5;28;01mNone\u001b[39;00m, fscope) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mtrainable_variables[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]],), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), fscope)\n\u001b[0;32m     30\u001b[0m sub_nets_init_weights \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39msub_nets_init_weights\n",
      "File \u001b[1;32mc:\\Users\\max-s\\Desktop\\Uni\\Master\\Masterthesis\\Code\\git\\overparametrized_dnn\\src\\my_dnn.py:65\u001b[0m, in \u001b[0;36mL1Projection.__call__\u001b[1;34m(self, w)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, w):\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_l1_projection(w)\n",
      "File \u001b[1;32mc:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_type.py:583\u001b[0m, in \u001b[0;36mcanonicalize_to_monomorphic\u001b[1;34m(args, kwargs, default_values, capture_types, polymorphic_type)\u001b[0m\n\u001b[0;32m    577\u001b[0m       parameters\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    578\u001b[0m           _make_validated_mono_param(kwarg_name, arg[kwarg_name],\n\u001b[0;32m    579\u001b[0m                                      Parameter\u001b[38;5;241m.\u001b[39mKEYWORD_ONLY, type_context,\n\u001b[0;32m    580\u001b[0m                                      poly_parameter\u001b[38;5;241m.\u001b[39mtype_constraint))\n\u001b[0;32m    581\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    582\u001b[0m     parameters\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 583\u001b[0m         _make_validated_mono_param(name, arg, poly_parameter\u001b[38;5;241m.\u001b[39mkind,\n\u001b[0;32m    584\u001b[0m                                    type_context,\n\u001b[0;32m    585\u001b[0m                                    poly_parameter\u001b[38;5;241m.\u001b[39mtype_constraint))\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m FunctionType(parameters, capture_types), type_context\n",
      "File \u001b[1;32mc:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_type.py:522\u001b[0m, in \u001b[0;36m_make_validated_mono_param\u001b[1;34m(name, value, kind, type_context, poly_type)\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_validated_mono_param\u001b[39m(\n\u001b[0;32m    519\u001b[0m     name, value, kind, type_context, poly_type\n\u001b[0;32m    520\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Parameter:\n\u001b[0;32m    521\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Generates and validates a parameter for Monomorphic FunctionType.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 522\u001b[0m   mono_type \u001b[38;5;241m=\u001b[39m trace_type\u001b[38;5;241m.\u001b[39mfrom_value(value, type_context)\n\u001b[0;32m    524\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m poly_type \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mono_type\u001b[38;5;241m.\u001b[39mis_subtype_of(poly_type):\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` was expected to be of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpoly_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmono_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\tensorflow\\core\\function\\trace_type\\trace_type_builder.py:185\u001b[0m, in \u001b[0;36mfrom_value\u001b[1;34m(value, context)\u001b[0m\n\u001b[0;32m    178\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m default_types\u001b[38;5;241m.\u001b[39mAttrs\u001b[38;5;241m.\u001b[39mfrom_type_and_attributes(\n\u001b[0;32m    179\u001b[0m       \u001b[38;5;28mtype\u001b[39m(value),\n\u001b[0;32m    180\u001b[0m       \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m    181\u001b[0m           from_value(\u001b[38;5;28mgetattr\u001b[39m(value, a\u001b[38;5;241m.\u001b[39mname), context)\n\u001b[0;32m    182\u001b[0m           \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__attrs_attrs__))\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m util\u001b[38;5;241m.\u001b[39mis_np_ndarray(value):\n\u001b[1;32m--> 185\u001b[0m   ndarray \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39m__array__()\n\u001b[0;32m    186\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m default_types\u001b[38;5;241m.\u001b[39mTENSOR(ndarray\u001b[38;5;241m.\u001b[39mshape, ndarray\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, custom_nest_protocol\u001b[38;5;241m.\u001b[39mCustomNestProtocol):\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: in user code:\n\n    File \"c:\\Users\\max-s\\Desktop\\Uni\\Master\\Masterthesis\\Code\\git\\overparametrized_dnn\\src\\my_dnn.py\", line 176, in train_step  *\n        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 269, in apply_gradients  **\n        self.apply(grads, trainable_variables)\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 334, in apply\n        variable.assign(variable.constraint(variable))\n    File \"c:\\Users\\max-s\\Desktop\\Uni\\Master\\Masterthesis\\Code\\git\\overparametrized_dnn\\src\\my_dnn.py\", line 65, in __call__\n        return self.apply_l1_projection(w)\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_type.py\", line 583, in canonicalize_to_monomorphic\n        _make_validated_mono_param(name, arg, poly_parameter.kind,\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_type.py\", line 522, in _make_validated_mono_param\n        mono_type = trace_type.from_value(value, type_context)\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\tensorflow\\core\\function\\trace_type\\trace_type_builder.py\", line 185, in from_value\n        ndarray = value.__array__()\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\backend\\common\\variables.py\", line 198, in __array__\n        return np.asarray(self.value.__array__(dtype))\n\n    NotImplementedError: numpy() is only available when eager execution is enabled.\n"
     ]
    }
   ],
   "source": [
    "mses = []  # Initialize empty list to store MSEs\n",
    "maes = []  # Initialize empty list to store MAEs\n",
    "for _ in range(1):\n",
    "    x_train, y_train = get_data(\n",
    "        regression_func, x_dim=input_dim, num_samples=100, sigma=0.05\n",
    "    )\n",
    "    x_test, y_test = get_data(\n",
    "        regression_func, x_dim=input_dim, num_samples=10**5, sigma=0.05\n",
    "    )\n",
    "\n",
    "    # Preprocess data\n",
    "    train_data = preprocess(x_train, y_train, batch_size=100, training=True)\n",
    "    test_data = preprocess(x_test, y_test, batch_size=100, training=False)\n",
    "\n",
    "    model = create_dnn(\n",
    "        train_shape=x_train.shape,  # Beispielwerte\n",
    "        num_networks=160,\n",
    "        num_layers=10,\n",
    "        num_neurons=20,\n",
    "        beta=80,\n",
    "        gamma=80,\n",
    "        delta=1,\n",
    "    )\n",
    "\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=np.exp(-15))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"mean_squared_error\", metrics=[\"mean_squared_error\"]\n",
    "    )\n",
    "    mse, mae = train_and_evaluate_dnn(model, train_data, test_data, epochs=500)\n",
    "    mses.append(mse)\n",
    "    maes.append(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95123291015625]\n"
     ]
    }
   ],
   "source": [
    "print(mses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = create_dnn(\n",
    "        train_shape=x_train.shape,  # Beispielwerte\n",
    "        num_networks=160,\n",
    "        num_layers=10,\n",
    "        num_neurons=20,\n",
    "        beta=80,\n",
    "        gamma=80,\n",
    "        delta=1,\n",
    "    )\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=np.exp(-14))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer, loss=\"mean_squared_error\", metrics=[\"mean_squared_error\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 855s 58s/step - loss: 13.4205 - val_loss: 1.8008 - val_mean_squared_error: 1.8008\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 1.8321 - val_loss: 1.8104 - val_mean_squared_error: 1.8104\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 1s 367ms/step - loss: 1.8741 - val_loss: 1.7685 - val_mean_squared_error: 1.7685\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 1s 379ms/step - loss: 1.8196 - val_loss: 1.7667 - val_mean_squared_error: 1.7667\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 1s 366ms/step - loss: 1.7788 - val_loss: 1.8199 - val_mean_squared_error: 1.8199\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 1s 401ms/step - loss: 1.7572 - val_loss: 1.7835 - val_mean_squared_error: 1.7835\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 1s 379ms/step - loss: 1.7855 - val_loss: 1.7095 - val_mean_squared_error: 1.7095\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 1s 397ms/step - loss: 1.7267 - val_loss: 1.7383 - val_mean_squared_error: 1.7383\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 1s 544ms/step - loss: 1.7610 - val_loss: 1.6794 - val_mean_squared_error: 1.6794\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 1s 551ms/step - loss: 1.7329 - val_loss: 1.7707 - val_mean_squared_error: 1.7707\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 1s 376ms/step - loss: 1.7061 - val_loss: 1.7259 - val_mean_squared_error: 1.7259\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 1s 549ms/step - loss: 1.6707 - val_loss: 1.6570 - val_mean_squared_error: 1.6570\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 1s 383ms/step - loss: 1.6639 - val_loss: 1.6955 - val_mean_squared_error: 1.6955\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 1.6745 - val_loss: 1.7000 - val_mean_squared_error: 1.7000\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 1s 669ms/step - loss: 1.7138 - val_loss: 1.7239 - val_mean_squared_error: 1.7239\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 1s 523ms/step - loss: 1.6520 - val_loss: 1.6632 - val_mean_squared_error: 1.6632\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 1s 483ms/step - loss: 1.6085 - val_loss: 1.5883 - val_mean_squared_error: 1.5883\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 1s 519ms/step - loss: 1.6057 - val_loss: 1.5715 - val_mean_squared_error: 1.5715\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 1s 441ms/step - loss: 1.6020 - val_loss: 1.6340 - val_mean_squared_error: 1.6340\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 1s 472ms/step - loss: 1.5756 - val_loss: 1.5896 - val_mean_squared_error: 1.5896\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 1.5515 - val_loss: 1.5563 - val_mean_squared_error: 1.5563\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 1s 1s/step - loss: 1.5409 - val_loss: 1.5383 - val_mean_squared_error: 1.5383\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 1s 606ms/step - loss: 1.6562 - val_loss: 1.6603 - val_mean_squared_error: 1.6603\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 1s 507ms/step - loss: 1.5389 - val_loss: 1.5256 - val_mean_squared_error: 1.5256\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 1s 485ms/step - loss: 1.5117 - val_loss: 1.4928 - val_mean_squared_error: 1.4928\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 1s 513ms/step - loss: 1.4946 - val_loss: 1.5005 - val_mean_squared_error: 1.5005\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 1s 552ms/step - loss: 1.4869 - val_loss: 1.5023 - val_mean_squared_error: 1.5023\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 1s 495ms/step - loss: 1.5032 - val_loss: 1.4459 - val_mean_squared_error: 1.4459\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 1s 392ms/step - loss: 1.5154 - val_loss: 1.5401 - val_mean_squared_error: 1.5401\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 1s 364ms/step - loss: 1.4605 - val_loss: 1.4436 - val_mean_squared_error: 1.4436\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 1s 351ms/step - loss: 1.5172 - val_loss: 1.4066 - val_mean_squared_error: 1.4066\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 1.4786 - val_loss: 1.4051 - val_mean_squared_error: 1.4051\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 1s 365ms/step - loss: 1.4244 - val_loss: 1.4243 - val_mean_squared_error: 1.4243\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 1s 395ms/step - loss: 1.4108 - val_loss: 1.4094 - val_mean_squared_error: 1.4094\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 1s 360ms/step - loss: 1.4263 - val_loss: 1.3759 - val_mean_squared_error: 1.3759\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 1.3983 - val_loss: 1.4143 - val_mean_squared_error: 1.4143\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 1s 347ms/step - loss: 1.3852 - val_loss: 1.3719 - val_mean_squared_error: 1.3719\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 1s 480ms/step - loss: 1.3934 - val_loss: 1.4146 - val_mean_squared_error: 1.4146\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 1s 386ms/step - loss: 1.3660 - val_loss: 1.3585 - val_mean_squared_error: 1.3585\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 1s 365ms/step - loss: 1.4086 - val_loss: 1.3222 - val_mean_squared_error: 1.3222\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 3s 472ms/step - loss: 1.3521 - val_loss: 1.3479 - val_mean_squared_error: 1.3479\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 1s 373ms/step - loss: 1.3359 - val_loss: 1.3444 - val_mean_squared_error: 1.3444\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 1.3267 - val_loss: 1.3267 - val_mean_squared_error: 1.3267\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 1.3208 - val_loss: 1.3333 - val_mean_squared_error: 1.3333\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 1s 374ms/step - loss: 1.3184 - val_loss: 1.2933 - val_mean_squared_error: 1.2933\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 1.3065 - val_loss: 1.3231 - val_mean_squared_error: 1.3231\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 1s 367ms/step - loss: 1.2977 - val_loss: 1.2796 - val_mean_squared_error: 1.2796\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 1s 393ms/step - loss: 1.2888 - val_loss: 1.2757 - val_mean_squared_error: 1.2757\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 1.2854 - val_loss: 1.3044 - val_mean_squared_error: 1.3044\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 1s 351ms/step - loss: 1.2830 - val_loss: 1.2962 - val_mean_squared_error: 1.2962\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 1.2613 - val_loss: 1.2524 - val_mean_squared_error: 1.2524\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 1s 566ms/step - loss: 1.2638 - val_loss: 1.2362 - val_mean_squared_error: 1.2362\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 1s 378ms/step - loss: 1.4348 - val_loss: 1.2167 - val_mean_squared_error: 1.2167\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 1s 350ms/step - loss: 1.2741 - val_loss: 1.2821 - val_mean_squared_error: 1.2821\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 1s 354ms/step - loss: 1.3544 - val_loss: 1.3386 - val_mean_squared_error: 1.3386\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 1s 369ms/step - loss: 1.2537 - val_loss: 1.2483 - val_mean_squared_error: 1.2483\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 1.2523 - val_loss: 1.1891 - val_mean_squared_error: 1.1891\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 1s 369ms/step - loss: 1.2182 - val_loss: 1.1991 - val_mean_squared_error: 1.1991\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 1.2091 - val_loss: 1.2321 - val_mean_squared_error: 1.2321\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 1s 408ms/step - loss: 1.2053 - val_loss: 1.2221 - val_mean_squared_error: 1.2221\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 1s 412ms/step - loss: 1.2031 - val_loss: 1.1674 - val_mean_squared_error: 1.1674\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 1s 364ms/step - loss: 1.1942 - val_loss: 1.1660 - val_mean_squared_error: 1.1660\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 1.1781 - val_loss: 1.1645 - val_mean_squared_error: 1.1645\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 1s 360ms/step - loss: 1.1628 - val_loss: 1.1726 - val_mean_squared_error: 1.1726\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 1s 366ms/step - loss: 1.1559 - val_loss: 1.1595 - val_mean_squared_error: 1.1595\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 1s 408ms/step - loss: 1.1491 - val_loss: 1.1632 - val_mean_squared_error: 1.1632\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 1s 617ms/step - loss: 1.1680 - val_loss: 1.1935 - val_mean_squared_error: 1.1935\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 1s 352ms/step - loss: 1.1732 - val_loss: 1.1896 - val_mean_squared_error: 1.1896\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 1s 422ms/step - loss: 1.1504 - val_loss: 1.1680 - val_mean_squared_error: 1.1680\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 1s 411ms/step - loss: 1.1248 - val_loss: 1.1389 - val_mean_squared_error: 1.1389\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 1s 395ms/step - loss: 1.1239 - val_loss: 1.1494 - val_mean_squared_error: 1.1494\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 1.1347 - val_loss: 1.1598 - val_mean_squared_error: 1.1598\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 1s 346ms/step - loss: 1.1103 - val_loss: 1.1287 - val_mean_squared_error: 1.1287\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 1s 366ms/step - loss: 1.0975 - val_loss: 1.1131 - val_mean_squared_error: 1.1131\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 1.1269 - val_loss: 1.0820 - val_mean_squared_error: 1.0820\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 1s 372ms/step - loss: 1.0901 - val_loss: 1.1056 - val_mean_squared_error: 1.1056\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 1s 433ms/step - loss: 1.0807 - val_loss: 1.1054 - val_mean_squared_error: 1.1054\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 1s 432ms/step - loss: 1.1139 - val_loss: 1.1418 - val_mean_squared_error: 1.1418\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 1s 398ms/step - loss: 1.0809 - val_loss: 1.1013 - val_mean_squared_error: 1.1013\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 1s 382ms/step - loss: 1.0690 - val_loss: 1.0970 - val_mean_squared_error: 1.0970\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 1s 378ms/step - loss: 1.0577 - val_loss: 1.0813 - val_mean_squared_error: 1.0813\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 1s 406ms/step - loss: 1.0518 - val_loss: 1.0752 - val_mean_squared_error: 1.0752\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 1s 382ms/step - loss: 1.0711 - val_loss: 1.0450 - val_mean_squared_error: 1.0450\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 1s 341ms/step - loss: 1.0561 - val_loss: 1.0474 - val_mean_squared_error: 1.0474\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 1.0366 - val_loss: 1.0645 - val_mean_squared_error: 1.0645\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 1s 369ms/step - loss: 1.0297 - val_loss: 1.0557 - val_mean_squared_error: 1.0557\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 1.0363 - val_loss: 1.0729 - val_mean_squared_error: 1.0729\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 1.0241 - val_loss: 1.0339 - val_mean_squared_error: 1.0339\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 1s 413ms/step - loss: 1.0160 - val_loss: 1.0491 - val_mean_squared_error: 1.0491\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 1.0131 - val_loss: 1.0245 - val_mean_squared_error: 1.0245\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 1.0047 - val_loss: 1.0294 - val_mean_squared_error: 1.0294\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 1s 409ms/step - loss: 0.9989 - val_loss: 1.0257 - val_mean_squared_error: 1.0257\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 1s 388ms/step - loss: 1.0148 - val_loss: 1.0572 - val_mean_squared_error: 1.0572\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 1s 376ms/step - loss: 1.0013 - val_loss: 1.0362 - val_mean_squared_error: 1.0362\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 3s 367ms/step - loss: 0.9990 - val_loss: 1.0390 - val_mean_squared_error: 1.0390\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 1s 350ms/step - loss: 0.9853 - val_loss: 0.9995 - val_mean_squared_error: 0.9995\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 1s 350ms/step - loss: 0.9790 - val_loss: 1.0209 - val_mean_squared_error: 1.0209\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 1.0185 - val_loss: 1.0566 - val_mean_squared_error: 1.0566\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 1s 404ms/step - loss: 1.0052 - val_loss: 0.9774 - val_mean_squared_error: 0.9774\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 0.9736 - val_loss: 0.9873 - val_mean_squared_error: 0.9873\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.9589 - val_loss: 0.9876 - val_mean_squared_error: 0.9876\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 1s 485ms/step - loss: 1.0477 - val_loss: 1.0771 - val_mean_squared_error: 1.0771\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 0.9616 - val_loss: 0.9810 - val_mean_squared_error: 0.9810\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 0.9587 - val_loss: 0.9658 - val_mean_squared_error: 0.9658\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 1s 341ms/step - loss: 0.9467 - val_loss: 0.9693 - val_mean_squared_error: 0.9693\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 1s 364ms/step - loss: 0.9402 - val_loss: 0.9910 - val_mean_squared_error: 0.9910\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 0.9422 - val_loss: 0.9568 - val_mean_squared_error: 0.9568\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 1s 367ms/step - loss: 0.9471 - val_loss: 1.0021 - val_mean_squared_error: 1.0021\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 1s 364ms/step - loss: 0.9264 - val_loss: 0.9579 - val_mean_squared_error: 0.9579\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 0.9183 - val_loss: 0.9668 - val_mean_squared_error: 0.9668\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 1s 349ms/step - loss: 0.9247 - val_loss: 0.9794 - val_mean_squared_error: 0.9794\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 1s 388ms/step - loss: 0.9316 - val_loss: 0.9847 - val_mean_squared_error: 0.9847\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 1s 388ms/step - loss: 0.9101 - val_loss: 0.9591 - val_mean_squared_error: 0.9591\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 1s 375ms/step - loss: 0.9055 - val_loss: 0.9612 - val_mean_squared_error: 0.9612\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 1s 381ms/step - loss: 0.8991 - val_loss: 0.9518 - val_mean_squared_error: 0.9518\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 0.9180 - val_loss: 0.9268 - val_mean_squared_error: 0.9268\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 1s 360ms/step - loss: 0.8994 - val_loss: 0.9334 - val_mean_squared_error: 0.9334\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 0.8880 - val_loss: 0.9358 - val_mean_squared_error: 0.9358\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 0.9303 - val_loss: 0.9165 - val_mean_squared_error: 0.9165\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 1s 377ms/step - loss: 0.8991 - val_loss: 0.9631 - val_mean_squared_error: 0.9631\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 1s 356ms/step - loss: 0.8782 - val_loss: 0.9271 - val_mean_squared_error: 0.9271\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 1s 390ms/step - loss: 0.8727 - val_loss: 0.9247 - val_mean_squared_error: 0.9247\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 1s 380ms/step - loss: 0.8956 - val_loss: 0.9086 - val_mean_squared_error: 0.9086\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 1s 380ms/step - loss: 0.8717 - val_loss: 0.9177 - val_mean_squared_error: 0.9177\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 1s 344ms/step - loss: 0.8684 - val_loss: 0.9376 - val_mean_squared_error: 0.9376\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.8608 - val_loss: 0.9117 - val_mean_squared_error: 0.9117\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 1s 361ms/step - loss: 0.8677 - val_loss: 0.9029 - val_mean_squared_error: 0.9029\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 1s 374ms/step - loss: 0.8626 - val_loss: 0.9351 - val_mean_squared_error: 0.9351\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 0.8628 - val_loss: 0.9304 - val_mean_squared_error: 0.9304\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 1s 342ms/step - loss: 0.8591 - val_loss: 0.8945 - val_mean_squared_error: 0.8945\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.8458 - val_loss: 0.9020 - val_mean_squared_error: 0.9020\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 1s 415ms/step - loss: 0.8628 - val_loss: 0.8882 - val_mean_squared_error: 0.8882\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.8401 - val_loss: 0.8979 - val_mean_squared_error: 0.8979\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 1s 455ms/step - loss: 0.8316 - val_loss: 0.9013 - val_mean_squared_error: 0.9013\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 1s 383ms/step - loss: 0.8638 - val_loss: 0.9373 - val_mean_squared_error: 0.9373\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 1s 371ms/step - loss: 0.8304 - val_loss: 0.8913 - val_mean_squared_error: 0.8913\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 1s 365ms/step - loss: 0.8330 - val_loss: 0.9128 - val_mean_squared_error: 0.9128\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 1s 372ms/step - loss: 0.8642 - val_loss: 0.9330 - val_mean_squared_error: 0.9330\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 1s 346ms/step - loss: 0.8445 - val_loss: 0.9138 - val_mean_squared_error: 0.9138\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.8164 - val_loss: 0.8899 - val_mean_squared_error: 0.8899\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 1s 395ms/step - loss: 0.8113 - val_loss: 0.8803 - val_mean_squared_error: 0.8803\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 1s 378ms/step - loss: 0.8083 - val_loss: 0.8799 - val_mean_squared_error: 0.8799\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 1s 370ms/step - loss: 0.8054 - val_loss: 0.8874 - val_mean_squared_error: 0.8874\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 1s 356ms/step - loss: 0.8028 - val_loss: 0.8843 - val_mean_squared_error: 0.8843\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 0.8015 - val_loss: 0.8707 - val_mean_squared_error: 0.8707\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 0.7975 - val_loss: 0.8717 - val_mean_squared_error: 0.8717\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 1s 400ms/step - loss: 0.8255 - val_loss: 0.8591 - val_mean_squared_error: 0.8591\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 1s 453ms/step - loss: 0.7950 - val_loss: 0.8784 - val_mean_squared_error: 0.8784\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 1s 375ms/step - loss: 0.7891 - val_loss: 0.8658 - val_mean_squared_error: 0.8658\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 1s 377ms/step - loss: 0.8216 - val_loss: 0.8542 - val_mean_squared_error: 0.8542\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 1s 356ms/step - loss: 0.7925 - val_loss: 0.8618 - val_mean_squared_error: 0.8618\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 1s 378ms/step - loss: 0.7822 - val_loss: 0.8614 - val_mean_squared_error: 0.8614\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 0.7810 - val_loss: 0.8756 - val_mean_squared_error: 0.8756\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 1s 411ms/step - loss: 0.7848 - val_loss: 0.8793 - val_mean_squared_error: 0.8793\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 3s 473ms/step - loss: 0.7737 - val_loss: 0.8574 - val_mean_squared_error: 0.8574\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 1s 381ms/step - loss: 0.7703 - val_loss: 0.8572 - val_mean_squared_error: 0.8572\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 1s 350ms/step - loss: 0.7756 - val_loss: 0.8491 - val_mean_squared_error: 0.8491\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 1s 351ms/step - loss: 0.8050 - val_loss: 0.8430 - val_mean_squared_error: 0.8430\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 1s 369ms/step - loss: 0.7766 - val_loss: 0.8474 - val_mean_squared_error: 0.8474\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 1s 400ms/step - loss: 0.7658 - val_loss: 0.8683 - val_mean_squared_error: 0.8683\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 1s 421ms/step - loss: 0.7616 - val_loss: 0.8613 - val_mean_squared_error: 0.8613\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 1s 382ms/step - loss: 0.7565 - val_loss: 0.8559 - val_mean_squared_error: 0.8559\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 1s 372ms/step - loss: 0.7636 - val_loss: 0.8399 - val_mean_squared_error: 0.8399\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 1s 351ms/step - loss: 0.7556 - val_loss: 0.8435 - val_mean_squared_error: 0.8435\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 1s 361ms/step - loss: 0.7487 - val_loss: 0.8526 - val_mean_squared_error: 0.8526\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 1s 373ms/step - loss: 0.7463 - val_loss: 0.8499 - val_mean_squared_error: 0.8499\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 0.7512 - val_loss: 0.8361 - val_mean_squared_error: 0.8361\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 1s 391ms/step - loss: 0.7419 - val_loss: 0.8461 - val_mean_squared_error: 0.8461\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 1s 367ms/step - loss: 0.7834 - val_loss: 0.8848 - val_mean_squared_error: 0.8848\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 1s 383ms/step - loss: 0.7470 - val_loss: 0.8482 - val_mean_squared_error: 0.8482\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 1s 409ms/step - loss: 0.7461 - val_loss: 0.8302 - val_mean_squared_error: 0.8302\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.7412 - val_loss: 0.8323 - val_mean_squared_error: 0.8323\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 1s 606ms/step - loss: 0.7333 - val_loss: 0.8340 - val_mean_squared_error: 0.8340\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 0.7344 - val_loss: 0.8507 - val_mean_squared_error: 0.8507\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 1s 355ms/step - loss: 0.7291 - val_loss: 0.8424 - val_mean_squared_error: 0.8424\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 1s 381ms/step - loss: 0.7303 - val_loss: 0.8470 - val_mean_squared_error: 0.8470\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 1s 376ms/step - loss: 0.7231 - val_loss: 0.8302 - val_mean_squared_error: 0.8302\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.7243 - val_loss: 0.8271 - val_mean_squared_error: 0.8271\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 1s 428ms/step - loss: 0.7200 - val_loss: 0.8396 - val_mean_squared_error: 0.8396\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 1s 336ms/step - loss: 0.7281 - val_loss: 0.8485 - val_mean_squared_error: 0.8485\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 1s 372ms/step - loss: 0.7567 - val_loss: 0.8671 - val_mean_squared_error: 0.8671\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 1s 401ms/step - loss: 0.7252 - val_loss: 0.8201 - val_mean_squared_error: 0.8201\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 1s 369ms/step - loss: 0.7115 - val_loss: 0.8284 - val_mean_squared_error: 0.8284\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 1s 581ms/step - loss: 0.7086 - val_loss: 0.8244 - val_mean_squared_error: 0.8244\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 1s 410ms/step - loss: 0.7059 - val_loss: 0.8293 - val_mean_squared_error: 0.8293\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.7097 - val_loss: 0.8188 - val_mean_squared_error: 0.8188\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 1s 350ms/step - loss: 0.7034 - val_loss: 0.8235 - val_mean_squared_error: 0.8235\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 0.7001 - val_loss: 0.8271 - val_mean_squared_error: 0.8271\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 1s 373ms/step - loss: 0.6982 - val_loss: 0.8263 - val_mean_squared_error: 0.8263\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 1s 438ms/step - loss: 0.7111 - val_loss: 0.8135 - val_mean_squared_error: 0.8135\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 1s 425ms/step - loss: 0.6964 - val_loss: 0.8232 - val_mean_squared_error: 0.8232\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 1s 390ms/step - loss: 0.6957 - val_loss: 0.8298 - val_mean_squared_error: 0.8298\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 1s 383ms/step - loss: 0.7074 - val_loss: 0.8407 - val_mean_squared_error: 0.8407\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 1s 389ms/step - loss: 0.6925 - val_loss: 0.8153 - val_mean_squared_error: 0.8153\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 1s 348ms/step - loss: 0.6874 - val_loss: 0.8223 - val_mean_squared_error: 0.8223\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 1s 365ms/step - loss: 0.7104 - val_loss: 0.8455 - val_mean_squared_error: 0.8455\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 1s 426ms/step - loss: 0.7533 - val_loss: 0.8650 - val_mean_squared_error: 0.8650\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 1s 399ms/step - loss: 0.6949 - val_loss: 0.8233 - val_mean_squared_error: 0.8233\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 1s 374ms/step - loss: 0.6814 - val_loss: 0.8207 - val_mean_squared_error: 0.8207\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 1s 371ms/step - loss: 0.6936 - val_loss: 0.8072 - val_mean_squared_error: 0.8072\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 1s 518ms/step - loss: 0.6800 - val_loss: 0.8217 - val_mean_squared_error: 0.8217\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 1s 352ms/step - loss: 0.6785 - val_loss: 0.8218 - val_mean_squared_error: 0.8218\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 1s 561ms/step - loss: 0.6992 - val_loss: 0.8050 - val_mean_squared_error: 0.8050\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.6804 - val_loss: 0.8094 - val_mean_squared_error: 0.8094\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 1s 446ms/step - loss: 0.6729 - val_loss: 0.8206 - val_mean_squared_error: 0.8206\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 1s 351ms/step - loss: 0.7005 - val_loss: 0.8418 - val_mean_squared_error: 0.8418\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 1s 402ms/step - loss: 0.6836 - val_loss: 0.8263 - val_mean_squared_error: 0.8263\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 1s 370ms/step - loss: 0.6810 - val_loss: 0.8285 - val_mean_squared_error: 0.8285\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 3s 727ms/step - loss: 0.6724 - val_loss: 0.8039 - val_mean_squared_error: 0.8039\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 1s 371ms/step - loss: 0.6630 - val_loss: 0.8113 - val_mean_squared_error: 0.8113\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 1s 380ms/step - loss: 0.6706 - val_loss: 0.8255 - val_mean_squared_error: 0.8255\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 1s 349ms/step - loss: 0.6600 - val_loss: 0.8087 - val_mean_squared_error: 0.8087\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 0.6599 - val_loss: 0.8170 - val_mean_squared_error: 0.8170\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 1s 427ms/step - loss: 0.6560 - val_loss: 0.8083 - val_mean_squared_error: 0.8083\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 1s 524ms/step - loss: 0.6543 - val_loss: 0.8081 - val_mean_squared_error: 0.8081\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 1s 642ms/step - loss: 0.6532 - val_loss: 0.8063 - val_mean_squared_error: 0.8063\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 1s 558ms/step - loss: 0.6532 - val_loss: 0.8145 - val_mean_squared_error: 0.8145\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 1s 529ms/step - loss: 0.6794 - val_loss: 0.7995 - val_mean_squared_error: 0.7995\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 1s 411ms/step - loss: 0.6652 - val_loss: 0.8007 - val_mean_squared_error: 0.8007\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 1s 410ms/step - loss: 0.6503 - val_loss: 0.8144 - val_mean_squared_error: 0.8144\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 1s 656ms/step - loss: 0.6463 - val_loss: 0.8091 - val_mean_squared_error: 0.8091\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 1s 412ms/step - loss: 0.6437 - val_loss: 0.8059 - val_mean_squared_error: 0.8059\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 1s 351ms/step - loss: 0.6478 - val_loss: 0.8006 - val_mean_squared_error: 0.8006\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 1s 381ms/step - loss: 0.6421 - val_loss: 0.8054 - val_mean_squared_error: 0.8054\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 1s 361ms/step - loss: 0.6476 - val_loss: 0.7994 - val_mean_squared_error: 0.7994\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 1s 370ms/step - loss: 0.6495 - val_loss: 0.8212 - val_mean_squared_error: 0.8212\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 1s 382ms/step - loss: 0.6386 - val_loss: 0.8034 - val_mean_squared_error: 0.8034\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 1s 352ms/step - loss: 0.6389 - val_loss: 0.8002 - val_mean_squared_error: 0.8002\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 1s 494ms/step - loss: 0.6368 - val_loss: 0.8111 - val_mean_squared_error: 0.8111\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 0.6451 - val_loss: 0.7976 - val_mean_squared_error: 0.7976\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.6548 - val_loss: 0.7970 - val_mean_squared_error: 0.7970\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 1s 423ms/step - loss: 0.6467 - val_loss: 0.8236 - val_mean_squared_error: 0.8236\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 1s 745ms/step - loss: 0.6478 - val_loss: 0.8192 - val_mean_squared_error: 0.8192\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 1s 699ms/step - loss: 0.6537 - val_loss: 0.7964 - val_mean_squared_error: 0.7964\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 1s 430ms/step - loss: 0.6375 - val_loss: 0.7987 - val_mean_squared_error: 0.7987\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 1s 480ms/step - loss: 0.6278 - val_loss: 0.7997 - val_mean_squared_error: 0.7997\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 1s 433ms/step - loss: 0.6235 - val_loss: 0.8029 - val_mean_squared_error: 0.8029\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 1s 369ms/step - loss: 0.6228 - val_loss: 0.8061 - val_mean_squared_error: 0.8061\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 1s 427ms/step - loss: 0.6229 - val_loss: 0.8081 - val_mean_squared_error: 0.8081\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 1s 424ms/step - loss: 0.6345 - val_loss: 0.8184 - val_mean_squared_error: 0.8184\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 1s 356ms/step - loss: 0.6230 - val_loss: 0.7980 - val_mean_squared_error: 0.7980\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 1s 412ms/step - loss: 0.6349 - val_loss: 0.7962 - val_mean_squared_error: 0.7962\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 1s 446ms/step - loss: 0.6227 - val_loss: 0.7985 - val_mean_squared_error: 0.7985\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 1s 683ms/step - loss: 0.6267 - val_loss: 0.8178 - val_mean_squared_error: 0.8178\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 1s 374ms/step - loss: 0.6213 - val_loss: 0.8103 - val_mean_squared_error: 0.8103\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 1s 366ms/step - loss: 0.6128 - val_loss: 0.8040 - val_mean_squared_error: 0.8040\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 1s 409ms/step - loss: 0.6134 - val_loss: 0.7985 - val_mean_squared_error: 0.7985\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 1s 370ms/step - loss: 0.6206 - val_loss: 0.8166 - val_mean_squared_error: 0.8166\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 1s 413ms/step - loss: 0.6111 - val_loss: 0.8046 - val_mean_squared_error: 0.8046\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 1s 350ms/step - loss: 0.6122 - val_loss: 0.7974 - val_mean_squared_error: 0.7974\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 1s 402ms/step - loss: 0.6096 - val_loss: 0.7990 - val_mean_squared_error: 0.7990\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 1s 383ms/step - loss: 0.6051 - val_loss: 0.8017 - val_mean_squared_error: 0.8017\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 1s 419ms/step - loss: 0.6039 - val_loss: 0.8045 - val_mean_squared_error: 0.8045\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 1s 361ms/step - loss: 0.6149 - val_loss: 0.7965 - val_mean_squared_error: 0.7965\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 1s 401ms/step - loss: 0.6047 - val_loss: 0.8000 - val_mean_squared_error: 0.8000\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 1s 367ms/step - loss: 0.6062 - val_loss: 0.8122 - val_mean_squared_error: 0.8122\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 1s 389ms/step - loss: 0.6026 - val_loss: 0.7985 - val_mean_squared_error: 0.7985\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 1s 415ms/step - loss: 0.6207 - val_loss: 0.7969 - val_mean_squared_error: 0.7969\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 1s 365ms/step - loss: 0.6087 - val_loss: 0.8166 - val_mean_squared_error: 0.8166\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 1s 370ms/step - loss: 0.6010 - val_loss: 0.8080 - val_mean_squared_error: 0.8080\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 1s 522ms/step - loss: 0.6582 - val_loss: 0.8440 - val_mean_squared_error: 0.8440\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 1s 376ms/step - loss: 0.6079 - val_loss: 0.8078 - val_mean_squared_error: 0.8078\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 1s 431ms/step - loss: 0.5927 - val_loss: 0.8040 - val_mean_squared_error: 0.8040\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 1s 387ms/step - loss: 0.5911 - val_loss: 0.8047 - val_mean_squared_error: 0.8047\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 1s 487ms/step - loss: 0.5997 - val_loss: 0.7980 - val_mean_squared_error: 0.7980\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 1s 390ms/step - loss: 0.5913 - val_loss: 0.8080 - val_mean_squared_error: 0.8080\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 0.5885 - val_loss: 0.8016 - val_mean_squared_error: 0.8016\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 0.5866 - val_loss: 0.8049 - val_mean_squared_error: 0.8049\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 3s 3s/step - loss: 0.5894 - val_loss: 0.8097 - val_mean_squared_error: 0.8097\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.5983 - val_loss: 0.7987 - val_mean_squared_error: 0.7987\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 1s 386ms/step - loss: 0.5932 - val_loss: 0.7996 - val_mean_squared_error: 0.7996\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 1s 384ms/step - loss: 0.5843 - val_loss: 0.8026 - val_mean_squared_error: 0.8026\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 1s 344ms/step - loss: 0.5839 - val_loss: 0.8095 - val_mean_squared_error: 0.8095\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 1s 370ms/step - loss: 0.5831 - val_loss: 0.8083 - val_mean_squared_error: 0.8083\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 1s 373ms/step - loss: 0.5797 - val_loss: 0.8038 - val_mean_squared_error: 0.8038\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.5798 - val_loss: 0.8080 - val_mean_squared_error: 0.8080\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 1s 387ms/step - loss: 0.5800 - val_loss: 0.8017 - val_mean_squared_error: 0.8017\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 1s 434ms/step - loss: 0.5779 - val_loss: 0.8033 - val_mean_squared_error: 0.8033\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 0.5879 - val_loss: 0.8189 - val_mean_squared_error: 0.8189\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 1s 488ms/step - loss: 0.5763 - val_loss: 0.8054 - val_mean_squared_error: 0.8054\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 1s 448ms/step - loss: 0.5738 - val_loss: 0.8069 - val_mean_squared_error: 0.8069\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 1s 454ms/step - loss: 0.5726 - val_loss: 0.8059 - val_mean_squared_error: 0.8059\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 1s 413ms/step - loss: 0.5717 - val_loss: 0.8076 - val_mean_squared_error: 0.8076\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 1s 408ms/step - loss: 0.5708 - val_loss: 0.8056 - val_mean_squared_error: 0.8056\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 1s 372ms/step - loss: 0.5784 - val_loss: 0.8172 - val_mean_squared_error: 0.8172\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 1s 393ms/step - loss: 0.5702 - val_loss: 0.8055 - val_mean_squared_error: 0.8055\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 1s 376ms/step - loss: 0.5726 - val_loss: 0.8037 - val_mean_squared_error: 0.8037\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 1s 610ms/step - loss: 0.5789 - val_loss: 0.8204 - val_mean_squared_error: 0.8204\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 1s 388ms/step - loss: 0.5678 - val_loss: 0.8067 - val_mean_squared_error: 0.8067\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 1s 385ms/step - loss: 0.5740 - val_loss: 0.8040 - val_mean_squared_error: 0.8040\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 1s 447ms/step - loss: 0.5673 - val_loss: 0.8131 - val_mean_squared_error: 0.8131\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 1s 429ms/step - loss: 0.5650 - val_loss: 0.8110 - val_mean_squared_error: 0.8110\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 0.5702 - val_loss: 0.8175 - val_mean_squared_error: 0.8175\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 1s 451ms/step - loss: 0.5691 - val_loss: 0.8054 - val_mean_squared_error: 0.8054\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 1s 372ms/step - loss: 0.5642 - val_loss: 0.8151 - val_mean_squared_error: 0.8151\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 1s 345ms/step - loss: 0.5789 - val_loss: 0.8063 - val_mean_squared_error: 0.8063\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 1s 518ms/step - loss: 0.5645 - val_loss: 0.8167 - val_mean_squared_error: 0.8167\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 1s 380ms/step - loss: 0.5673 - val_loss: 0.8190 - val_mean_squared_error: 0.8190\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 0.5637 - val_loss: 0.8169 - val_mean_squared_error: 0.8169\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 1s 384ms/step - loss: 0.5631 - val_loss: 0.8180 - val_mean_squared_error: 0.8180\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 1s 405ms/step - loss: 0.5637 - val_loss: 0.8077 - val_mean_squared_error: 0.8077\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 1s 375ms/step - loss: 0.5587 - val_loss: 0.8093 - val_mean_squared_error: 0.8093\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 1s 383ms/step - loss: 0.5562 - val_loss: 0.8169 - val_mean_squared_error: 0.8169\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 1s 360ms/step - loss: 0.5552 - val_loss: 0.8098 - val_mean_squared_error: 0.8098\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 1s 430ms/step - loss: 0.5564 - val_loss: 0.8193 - val_mean_squared_error: 0.8193\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 1s 379ms/step - loss: 0.5540 - val_loss: 0.8167 - val_mean_squared_error: 0.8167\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 1s 397ms/step - loss: 0.5622 - val_loss: 0.8101 - val_mean_squared_error: 0.8101\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 1s 377ms/step - loss: 0.5621 - val_loss: 0.8268 - val_mean_squared_error: 0.8268\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 1s 660ms/step - loss: 0.5518 - val_loss: 0.8120 - val_mean_squared_error: 0.8120\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 1s 396ms/step - loss: 0.5485 - val_loss: 0.8139 - val_mean_squared_error: 0.8139\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 1s 450ms/step - loss: 0.5470 - val_loss: 0.8156 - val_mean_squared_error: 0.8156\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 1s 386ms/step - loss: 0.5705 - val_loss: 0.8133 - val_mean_squared_error: 0.8133\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 1s 425ms/step - loss: 0.5533 - val_loss: 0.8139 - val_mean_squared_error: 0.8139\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 1s 371ms/step - loss: 0.5449 - val_loss: 0.8168 - val_mean_squared_error: 0.8168\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.5446 - val_loss: 0.8154 - val_mean_squared_error: 0.8154\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 1s 391ms/step - loss: 0.5433 - val_loss: 0.8176 - val_mean_squared_error: 0.8176\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 1s 379ms/step - loss: 0.5431 - val_loss: 0.8161 - val_mean_squared_error: 0.8161\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 1s 365ms/step - loss: 0.5414 - val_loss: 0.8180 - val_mean_squared_error: 0.8180\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 0.5419 - val_loss: 0.8215 - val_mean_squared_error: 0.8215\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 1s 519ms/step - loss: 0.5403 - val_loss: 0.8183 - val_mean_squared_error: 0.8183\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 1s 380ms/step - loss: 0.5396 - val_loss: 0.8215 - val_mean_squared_error: 0.8215\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 0.5463 - val_loss: 0.8282 - val_mean_squared_error: 0.8282\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 3s 3s/step - loss: 0.5386 - val_loss: 0.8196 - val_mean_squared_error: 0.8196\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 1s 385ms/step - loss: 0.5368 - val_loss: 0.8209 - val_mean_squared_error: 0.8209\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 1s 366ms/step - loss: 0.5359 - val_loss: 0.8222 - val_mean_squared_error: 0.8222\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 1s 375ms/step - loss: 0.5394 - val_loss: 0.8272 - val_mean_squared_error: 0.8272\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 1s 391ms/step - loss: 0.5475 - val_loss: 0.8326 - val_mean_squared_error: 0.8326\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.5458 - val_loss: 0.8198 - val_mean_squared_error: 0.8198\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 1s 383ms/step - loss: 0.5395 - val_loss: 0.8306 - val_mean_squared_error: 0.8306\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 1s 403ms/step - loss: 0.5352 - val_loss: 0.8213 - val_mean_squared_error: 0.8213\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 1s 367ms/step - loss: 0.5337 - val_loss: 0.8278 - val_mean_squared_error: 0.8278\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 1s 434ms/step - loss: 0.5318 - val_loss: 0.8262 - val_mean_squared_error: 0.8262\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 1s 387ms/step - loss: 0.5495 - val_loss: 0.8397 - val_mean_squared_error: 0.8397\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 1s 367ms/step - loss: 0.5343 - val_loss: 0.8279 - val_mean_squared_error: 0.8279\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 1s 450ms/step - loss: 0.5288 - val_loss: 0.8249 - val_mean_squared_error: 0.8249\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 1s 416ms/step - loss: 0.5297 - val_loss: 0.8245 - val_mean_squared_error: 0.8245\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 1s 396ms/step - loss: 0.5328 - val_loss: 0.8243 - val_mean_squared_error: 0.8243\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 1s 395ms/step - loss: 0.5274 - val_loss: 0.8265 - val_mean_squared_error: 0.8265\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 1s 688ms/step - loss: 0.5343 - val_loss: 0.8252 - val_mean_squared_error: 0.8252\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 1s 378ms/step - loss: 0.5496 - val_loss: 0.8267 - val_mean_squared_error: 0.8267\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 1s 381ms/step - loss: 0.5315 - val_loss: 0.8269 - val_mean_squared_error: 0.8269\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 1s 384ms/step - loss: 0.5274 - val_loss: 0.8273 - val_mean_squared_error: 0.8273\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 1s 817ms/step - loss: 0.5397 - val_loss: 0.8441 - val_mean_squared_error: 0.8441\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 1s 480ms/step - loss: 0.5248 - val_loss: 0.8294 - val_mean_squared_error: 0.8294\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 1s 375ms/step - loss: 0.5279 - val_loss: 0.8286 - val_mean_squared_error: 0.8286\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 1s 405ms/step - loss: 0.5435 - val_loss: 0.8300 - val_mean_squared_error: 0.8300\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 1s 379ms/step - loss: 0.5284 - val_loss: 0.8299 - val_mean_squared_error: 0.8299\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 1s 375ms/step - loss: 0.5204 - val_loss: 0.8347 - val_mean_squared_error: 0.8347\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 1s 601ms/step - loss: 0.5273 - val_loss: 0.8409 - val_mean_squared_error: 0.8409\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 1s 505ms/step - loss: 0.5278 - val_loss: 0.8407 - val_mean_squared_error: 0.8407\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 1s 471ms/step - loss: 0.5542 - val_loss: 0.8556 - val_mean_squared_error: 0.8556\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.5319 - val_loss: 0.8417 - val_mean_squared_error: 0.8417\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 1s 390ms/step - loss: 0.5692 - val_loss: 0.8631 - val_mean_squared_error: 0.8631\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 1s 390ms/step - loss: 0.5227 - val_loss: 0.8356 - val_mean_squared_error: 0.8356\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 1s 378ms/step - loss: 0.5180 - val_loss: 0.8343 - val_mean_squared_error: 0.8343\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 0.5187 - val_loss: 0.8348 - val_mean_squared_error: 0.8348\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 0.5142 - val_loss: 0.8395 - val_mean_squared_error: 0.8395\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 1s 377ms/step - loss: 0.5144 - val_loss: 0.8362 - val_mean_squared_error: 0.8362\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 1s 602ms/step - loss: 0.5138 - val_loss: 0.8371 - val_mean_squared_error: 0.8371\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 1s 395ms/step - loss: 0.5185 - val_loss: 0.8463 - val_mean_squared_error: 0.8463\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 1s 394ms/step - loss: 0.5187 - val_loss: 0.8452 - val_mean_squared_error: 0.8452\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 1s 369ms/step - loss: 0.5281 - val_loss: 0.8392 - val_mean_squared_error: 0.8392\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 1s 369ms/step - loss: 0.5286 - val_loss: 0.8389 - val_mean_squared_error: 0.8389\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 1s 373ms/step - loss: 0.5610 - val_loss: 0.8448 - val_mean_squared_error: 0.8448\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 1s 386ms/step - loss: 0.5163 - val_loss: 0.8466 - val_mean_squared_error: 0.8466\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 1s 379ms/step - loss: 0.5115 - val_loss: 0.8404 - val_mean_squared_error: 0.8404\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 1s 421ms/step - loss: 0.5076 - val_loss: 0.8427 - val_mean_squared_error: 0.8427\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 1s 776ms/step - loss: 0.5326 - val_loss: 0.8438 - val_mean_squared_error: 0.8438\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 1s 393ms/step - loss: 0.5103 - val_loss: 0.8434 - val_mean_squared_error: 0.8434\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 1s 432ms/step - loss: 0.5138 - val_loss: 0.8526 - val_mean_squared_error: 0.8526\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 1s 389ms/step - loss: 0.5177 - val_loss: 0.8534 - val_mean_squared_error: 0.8534\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 0.5260 - val_loss: 0.8458 - val_mean_squared_error: 0.8458\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 1s 381ms/step - loss: 0.5084 - val_loss: 0.8452 - val_mean_squared_error: 0.8452\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 0.5041 - val_loss: 0.8494 - val_mean_squared_error: 0.8494\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 1s 388ms/step - loss: 0.5234 - val_loss: 0.8610 - val_mean_squared_error: 0.8610\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 1s 349ms/step - loss: 0.5044 - val_loss: 0.8481 - val_mean_squared_error: 0.8481\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 1s 610ms/step - loss: 0.5007 - val_loss: 0.8483 - val_mean_squared_error: 0.8483\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 1s 609ms/step - loss: 0.5024 - val_loss: 0.8524 - val_mean_squared_error: 0.8524\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 1s 443ms/step - loss: 0.4999 - val_loss: 0.8493 - val_mean_squared_error: 0.8493\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.4999 - val_loss: 0.8492 - val_mean_squared_error: 0.8492\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 1s 370ms/step - loss: 0.5007 - val_loss: 0.8495 - val_mean_squared_error: 0.8495\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 1s 370ms/step - loss: 0.5060 - val_loss: 0.8591 - val_mean_squared_error: 0.8591\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 1s 388ms/step - loss: 0.4993 - val_loss: 0.8508 - val_mean_squared_error: 0.8508\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 3s 419ms/step - loss: 0.4973 - val_loss: 0.8520 - val_mean_squared_error: 0.8520\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 1s 374ms/step - loss: 0.4980 - val_loss: 0.8563 - val_mean_squared_error: 0.8563\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 1s 391ms/step - loss: 0.4958 - val_loss: 0.8535 - val_mean_squared_error: 0.8535\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 1s 422ms/step - loss: 0.4985 - val_loss: 0.8590 - val_mean_squared_error: 0.8590\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 1s 663ms/step - loss: 0.5028 - val_loss: 0.8538 - val_mean_squared_error: 0.8538\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 1s 382ms/step - loss: 0.4981 - val_loss: 0.8545 - val_mean_squared_error: 0.8545\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 1s 417ms/step - loss: 0.4933 - val_loss: 0.8561 - val_mean_squared_error: 0.8561\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 1s 403ms/step - loss: 0.5116 - val_loss: 0.8569 - val_mean_squared_error: 0.8569\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.4950 - val_loss: 0.8583 - val_mean_squared_error: 0.8583\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 1s 383ms/step - loss: 0.4977 - val_loss: 0.8641 - val_mean_squared_error: 0.8641\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 1s 389ms/step - loss: 0.5309 - val_loss: 0.8794 - val_mean_squared_error: 0.8794\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 1s 346ms/step - loss: 0.4964 - val_loss: 0.8602 - val_mean_squared_error: 0.8602\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 1s 381ms/step - loss: 0.4935 - val_loss: 0.8587 - val_mean_squared_error: 0.8587\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 1s 658ms/step - loss: 0.4897 - val_loss: 0.8615 - val_mean_squared_error: 0.8615\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 1s 383ms/step - loss: 0.4914 - val_loss: 0.8647 - val_mean_squared_error: 0.8647\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 1s 380ms/step - loss: 0.4910 - val_loss: 0.8606 - val_mean_squared_error: 0.8606\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 1s 419ms/step - loss: 0.4882 - val_loss: 0.8642 - val_mean_squared_error: 0.8642\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 1s 422ms/step - loss: 0.4872 - val_loss: 0.8631 - val_mean_squared_error: 0.8631\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 1s 382ms/step - loss: 0.4871 - val_loss: 0.8655 - val_mean_squared_error: 0.8655\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 1s 403ms/step - loss: 0.4856 - val_loss: 0.8645 - val_mean_squared_error: 0.8645\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 1s 402ms/step - loss: 0.4857 - val_loss: 0.8645 - val_mean_squared_error: 0.8645\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 1s 380ms/step - loss: 0.4859 - val_loss: 0.8647 - val_mean_squared_error: 0.8647\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 1s 408ms/step - loss: 0.4843 - val_loss: 0.8667 - val_mean_squared_error: 0.8667\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 1s 503ms/step - loss: 0.4879 - val_loss: 0.8715 - val_mean_squared_error: 0.8715\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 1s 378ms/step - loss: 0.4837 - val_loss: 0.8675 - val_mean_squared_error: 0.8675\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 0.4844 - val_loss: 0.8712 - val_mean_squared_error: 0.8712\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 1s 385ms/step - loss: 0.4837 - val_loss: 0.8709 - val_mean_squared_error: 0.8709\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 1s 377ms/step - loss: 0.4825 - val_loss: 0.8709 - val_mean_squared_error: 0.8709\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.4816 - val_loss: 0.8715 - val_mean_squared_error: 0.8715\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 1s 371ms/step - loss: 0.4906 - val_loss: 0.8783 - val_mean_squared_error: 0.8783\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 1s 388ms/step - loss: 0.4838 - val_loss: 0.8738 - val_mean_squared_error: 0.8738\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 1s 442ms/step - loss: 0.4819 - val_loss: 0.8748 - val_mean_squared_error: 0.8748\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 1s 381ms/step - loss: 0.4796 - val_loss: 0.8739 - val_mean_squared_error: 0.8739\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 1s 426ms/step - loss: 0.4810 - val_loss: 0.8724 - val_mean_squared_error: 0.8724\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 1s 548ms/step - loss: 0.4817 - val_loss: 0.8730 - val_mean_squared_error: 0.8730\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 1s 620ms/step - loss: 0.4809 - val_loss: 0.8786 - val_mean_squared_error: 0.8786\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 1s 392ms/step - loss: 0.4777 - val_loss: 0.8763 - val_mean_squared_error: 0.8763\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 1s 576ms/step - loss: 0.4769 - val_loss: 0.8774 - val_mean_squared_error: 0.8774\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 1s 416ms/step - loss: 0.4966 - val_loss: 0.8783 - val_mean_squared_error: 0.8783\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 1s 511ms/step - loss: 0.5044 - val_loss: 0.8787 - val_mean_squared_error: 0.8787\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 1s 538ms/step - loss: 0.4874 - val_loss: 0.8774 - val_mean_squared_error: 0.8774\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 1s 369ms/step - loss: 0.4800 - val_loss: 0.8779 - val_mean_squared_error: 0.8779\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 1s 519ms/step - loss: 0.4798 - val_loss: 0.8849 - val_mean_squared_error: 0.8849\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 1s 482ms/step - loss: 0.4788 - val_loss: 0.8793 - val_mean_squared_error: 0.8793\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 0.4739 - val_loss: 0.8820 - val_mean_squared_error: 0.8820\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 1s 436ms/step - loss: 0.4735 - val_loss: 0.8833 - val_mean_squared_error: 0.8833\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 1s 451ms/step - loss: 0.4721 - val_loss: 0.8816 - val_mean_squared_error: 0.8816\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 1s 469ms/step - loss: 0.4720 - val_loss: 0.8823 - val_mean_squared_error: 0.8823\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 1s 493ms/step - loss: 0.4710 - val_loss: 0.8831 - val_mean_squared_error: 0.8831\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 1s 520ms/step - loss: 0.4708 - val_loss: 0.8856 - val_mean_squared_error: 0.8856\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 1s 490ms/step - loss: 0.4813 - val_loss: 0.8925 - val_mean_squared_error: 0.8925\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.4952 - val_loss: 0.8889 - val_mean_squared_error: 0.8889\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 1s 438ms/step - loss: 0.4836 - val_loss: 0.8958 - val_mean_squared_error: 0.8958\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 1s 390ms/step - loss: 0.4740 - val_loss: 0.8861 - val_mean_squared_error: 0.8861\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 3s 525ms/step - loss: 0.4720 - val_loss: 0.8867 - val_mean_squared_error: 0.8867\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 1s 562ms/step - loss: 0.4678 - val_loss: 0.8893 - val_mean_squared_error: 0.8893\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.4762 - val_loss: 0.8886 - val_mean_squared_error: 0.8886\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 1s 390ms/step - loss: 0.4722 - val_loss: 0.8944 - val_mean_squared_error: 0.8944\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 1s 400ms/step - loss: 0.4768 - val_loss: 0.8904 - val_mean_squared_error: 0.8904\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 1s 387ms/step - loss: 0.4747 - val_loss: 0.8903 - val_mean_squared_error: 0.8903\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 1s 406ms/step - loss: 0.4674 - val_loss: 0.8944 - val_mean_squared_error: 0.8944\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 1s 431ms/step - loss: 0.4725 - val_loss: 0.8977 - val_mean_squared_error: 0.8977\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 1s 389ms/step - loss: 0.4779 - val_loss: 0.8938 - val_mean_squared_error: 0.8938\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 1s 384ms/step - loss: 0.4962 - val_loss: 0.8965 - val_mean_squared_error: 0.8965\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 0.4699 - val_loss: 0.8936 - val_mean_squared_error: 0.8936\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 1s 379ms/step - loss: 0.4681 - val_loss: 0.8942 - val_mean_squared_error: 0.8942\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 1s 641ms/step - loss: 0.4656 - val_loss: 0.8948 - val_mean_squared_error: 0.8948\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 1s 388ms/step - loss: 0.4620 - val_loss: 0.8973 - val_mean_squared_error: 0.8973\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 1s 398ms/step - loss: 0.4926 - val_loss: 0.9133 - val_mean_squared_error: 0.9133\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 1s 384ms/step - loss: 0.4681 - val_loss: 0.8972 - val_mean_squared_error: 0.8972\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 1s 611ms/step - loss: 0.4850 - val_loss: 0.9006 - val_mean_squared_error: 0.9006\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 1s 508ms/step - loss: 0.4632 - val_loss: 0.8991 - val_mean_squared_error: 0.8991\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 1s 390ms/step - loss: 0.4595 - val_loss: 0.8995 - val_mean_squared_error: 0.8995\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 1s 378ms/step - loss: 0.4703 - val_loss: 0.9080 - val_mean_squared_error: 0.9080\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 1s 384ms/step - loss: 0.4695 - val_loss: 0.9062 - val_mean_squared_error: 0.9062\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 1s 496ms/step - loss: 0.4686 - val_loss: 0.9022 - val_mean_squared_error: 0.9022\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 1s 399ms/step - loss: 0.4592 - val_loss: 0.9026 - val_mean_squared_error: 0.9026\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 1s 387ms/step - loss: 0.4571 - val_loss: 0.9030 - val_mean_squared_error: 0.9030\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 1s 367ms/step - loss: 0.4655 - val_loss: 0.9101 - val_mean_squared_error: 0.9101\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 1s 387ms/step - loss: 0.4619 - val_loss: 0.9041 - val_mean_squared_error: 0.9041\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 1s 395ms/step - loss: 0.4568 - val_loss: 0.9052 - val_mean_squared_error: 0.9052\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 1s 426ms/step - loss: 0.4559 - val_loss: 0.9066 - val_mean_squared_error: 0.9066\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 1s 426ms/step - loss: 0.4719 - val_loss: 0.9083 - val_mean_squared_error: 0.9083\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 1s 433ms/step - loss: 0.4658 - val_loss: 0.9071 - val_mean_squared_error: 0.9071\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 1s 441ms/step - loss: 0.4580 - val_loss: 0.9075 - val_mean_squared_error: 0.9075\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 1s 520ms/step - loss: 0.4808 - val_loss: 0.9123 - val_mean_squared_error: 0.9123\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 1s 375ms/step - loss: 0.4605 - val_loss: 0.9090 - val_mean_squared_error: 0.9090\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 1s 417ms/step - loss: 0.4531 - val_loss: 0.9104 - val_mean_squared_error: 0.9104\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 1s 369ms/step - loss: 0.4896 - val_loss: 0.9294 - val_mean_squared_error: 0.9294\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 1s 426ms/step - loss: 0.4754 - val_loss: 0.9194 - val_mean_squared_error: 0.9194\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 1s 432ms/step - loss: 0.4703 - val_loss: 0.9210 - val_mean_squared_error: 0.9210\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 1s 395ms/step - loss: 0.4543 - val_loss: 0.9126 - val_mean_squared_error: 0.9126\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 1s 393ms/step - loss: 0.4756 - val_loss: 0.9170 - val_mean_squared_error: 0.9170\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 1s 396ms/step - loss: 0.4557 - val_loss: 0.9141 - val_mean_squared_error: 0.9141\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 1s 633ms/step - loss: 0.4580 - val_loss: 0.9209 - val_mean_squared_error: 0.9209\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 1s 405ms/step - loss: 0.4565 - val_loss: 0.9159 - val_mean_squared_error: 0.9159\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 1s 394ms/step - loss: 0.4548 - val_loss: 0.9162 - val_mean_squared_error: 0.9162\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 1s 410ms/step - loss: 0.4505 - val_loss: 0.9192 - val_mean_squared_error: 0.9192\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 1s 393ms/step - loss: 0.4491 - val_loss: 0.9186 - val_mean_squared_error: 0.9186\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 1s 379ms/step - loss: 0.4483 - val_loss: 0.9184 - val_mean_squared_error: 0.9184\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 1s 428ms/step - loss: 0.4523 - val_loss: 0.9190 - val_mean_squared_error: 0.9190\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 0.4497 - val_loss: 0.9196 - val_mean_squared_error: 0.9196\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 1s 665ms/step - loss: 0.4541 - val_loss: 0.9261 - val_mean_squared_error: 0.9261\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 1s 378ms/step - loss: 0.4560 - val_loss: 0.9259 - val_mean_squared_error: 0.9259\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 1s 399ms/step - loss: 0.4602 - val_loss: 0.9290 - val_mean_squared_error: 0.9290\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 1s 434ms/step - loss: 0.4632 - val_loss: 0.9252 - val_mean_squared_error: 0.9252\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 1s 426ms/step - loss: 0.4595 - val_loss: 0.9320 - val_mean_squared_error: 0.9320\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 1s 394ms/step - loss: 0.4494 - val_loss: 0.9256 - val_mean_squared_error: 0.9256\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 1s 450ms/step - loss: 0.4493 - val_loss: 0.9281 - val_mean_squared_error: 0.9281\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 1s 384ms/step - loss: 0.4449 - val_loss: 0.9252 - val_mean_squared_error: 0.9252\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 1s 410ms/step - loss: 0.4497 - val_loss: 0.9304 - val_mean_squared_error: 0.9304\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 1s 387ms/step - loss: 0.4460 - val_loss: 0.9263 - val_mean_squared_error: 0.9263\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 1s 442ms/step - loss: 0.4687 - val_loss: 0.9310 - val_mean_squared_error: 0.9310\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 1s 434ms/step - loss: 0.4465 - val_loss: 0.9286 - val_mean_squared_error: 0.9286\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 3s 3s/step - loss: 0.4431 - val_loss: 0.9298 - val_mean_squared_error: 0.9298\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 1s 403ms/step - loss: 0.4421 - val_loss: 0.9297 - val_mean_squared_error: 0.9297\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 1s 445ms/step - loss: 0.4422 - val_loss: 0.9298 - val_mean_squared_error: 0.9298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2541b49b150>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, epochs=500, validation_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.0071 - mean_squared_error: 0.0071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.007052791304886341, 0.007052791304886341]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val, y_val = get_data(m1, x_dim=m1.expected_dim, num_samples=10**5)\n",
    "validation_data = preprocess(x_val, y_val, training=False)\n",
    "\n",
    "model.evaluate(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_l1_projection(self, w):\n",
    "    if tf.norm(w, ord=1) <= self:\n",
    "        return w\n",
    "    # Apply L1-projection on weight vector w\n",
    "    abs_w = tf.abs(w)\n",
    "\n",
    "    # Compute cumulative sum of the sorted absolute weights\n",
    "    u = tf.sort(abs_w, direction=\"DESCENDING\", axis=0)\n",
    "    svp = tf.cumsum(u, axis=0) - self\n",
    "    print(u.numpy())\n",
    "    print(svp)\n",
    "\n",
    "    # Find the position where the condition is violated for the first time\n",
    "    ratio = tf.math.divide(svp, tf.constant(tf.range(1, tf.size(u) + 1, dtype=tf.float32), shape=tf.shape(u)))\n",
    "    print(ratio.numpy())\n",
    "\n",
    "    # Compute the threshold value\n",
    "    theta = tf.reduce_max(tf.maximum(ratio, 0.0), axis=0)\n",
    "    print(theta.numpy())\n",
    "\n",
    "    return tf.math.sign(w) * tf.maximum(abs_w - theta, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "tf.Tensor(\n",
      "[[-6.]\n",
      " [-5.]\n",
      " [-4.]\n",
      " [-3.]\n",
      " [-2.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 2.]\n",
      " [ 3.]\n",
      " [ 4.]], shape=(11, 1), dtype=float32)\n",
      "[[-6.        ]\n",
      " [-2.5       ]\n",
      " [-1.3333334 ]\n",
      " [-0.75      ]\n",
      " [-0.4       ]\n",
      " [-0.16666667]\n",
      " [ 0.        ]\n",
      " [ 0.125     ]\n",
      " [ 0.22222222]\n",
      " [ 0.3       ]\n",
      " [ 0.36363637]]\n",
      "[0.36363637]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(11, 1), dtype=float32, numpy=\n",
       "array([[0.6363636],\n",
       "       [0.6363636],\n",
       "       [0.6363636],\n",
       "       [0.6363636],\n",
       "       [0.6363636],\n",
       "       [0.6363636],\n",
       "       [0.6363636],\n",
       "       [0.6363636],\n",
       "       [0.6363636],\n",
       "       [0.6363636],\n",
       "       [0.6363636]], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = tf.Variable(tf.ones(shape=(11, 1)), dtype=tf.float32)\n",
    "apply_l1_projection(7.0, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_norm_l1(model):\n",
    "    # Test if L1 projection of last layer worked\n",
    "    weights = tf.reshape(model.trainable_variables[-1], [-1])\n",
    "    norm = tf.norm(weights, ord=1)\n",
    "    print(f\"norm: {norm}, gamma: {model.gamma}\")\n",
    "\n",
    "\n",
    "def test_norm_l2(model):\n",
    "    # Test if L2 projection of inner weights worked\n",
    "    current_weights = tf.concat(\n",
    "        [tf.reshape(v, [-1]) for v in model.trainable_weights[:-1]], axis=0\n",
    "    )\n",
    "    sub_nets_init_weights = model.sub_nets_init_weights\n",
    "    diff = sub_nets_init_weights - current_weights\n",
    "    norm = tf.norm(diff)\n",
    "    print(f\"norm: {norm}, delta: {model.delta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm: 0.7622666954994202, gamma: 10\n",
      "norm: 0.0030101335141807795, delta: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_norm_l1(model)\n",
    "test_norm_l2(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py4ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
