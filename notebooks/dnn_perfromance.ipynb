{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\max-s\\Desktop\\Uni\\Master\\Masterthesis\\Code\\git\\overparametrized_dnn\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Working Directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from data.data_generator import get_data, preprocess\n",
    "from src.my_dnn import create_dnn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras_tuner as kt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_func(x):\n",
    "    return np.exp(np.linalg.norm(x, axis=1))\n",
    "\n",
    "input_dim = 7\n",
    "\n",
    "x, y = get_data(regression_func, x_dim=input_dim, num_samples=100, sigma=0.05)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "train_data = preprocess(x_train, y_train, batch_size=20, training=True)\n",
    "val_data = preprocess(x_val, y_val, batch_size=20, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    hp_units = hp.Int(\"units\", min_value=10, max_value=40, step=10)\n",
    "    hp_layers = hp.Int(\"layers\", min_value=5, max_value=20, step=5)\n",
    "    hp_nets = hp.Int(\"networks\", min_value=80, max_value=6 * 80, step=80)\n",
    "    hp_beta = hp.Float('beta', min_value=20, max_value=80)\n",
    "    hp_gamma = hp.Float('gamma', min_value=30, max_value=80)\n",
    "    hp_learning_rate = hp.Float(\n",
    "        \"learning_rate\", min_value=np.exp(-16), max_value=np.exp(-14), sampling=\"log\"\n",
    "    )\n",
    "\n",
    "    # Hier nutzen Sie Ihre angepasste `create_dnn` Funktion mit den hp-Argumenten\n",
    "    model = create_dnn(\n",
    "        train_shape=x_train.shape,  # Beispielwerte\n",
    "        num_networks=hp_nets,\n",
    "        num_layers=hp_layers,\n",
    "        num_neurons=hp_units,\n",
    "        beta=hp_beta,\n",
    "        gamma=hp_gamma,\n",
    "        delta=1,\n",
    "    )\n",
    "\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=hp_learning_rate)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"mean_squared_error\", metrics=[\"mean_squared_error\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "30                |30                |units\n",
      "20                |20                |layers\n",
      "480               |480               |networks\n",
      "32.189            |32.189            |beta\n",
      "59.044            |59.044            |gamma\n",
      "2.9852e-07        |2.9852e-07        |learning_rate\n",
      "\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:From c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    model_builder,\n",
    "    objective='val_loss',\n",
    "    max_trials=20,\n",
    "    executions_per_trial=2,\n",
    "    directory='my_dir',\n",
    "    project_name='keras_tuner_2003'\n",
    ")\n",
    "\n",
    "# Starten des Tuning-Prozesses\n",
    "tuner.search(x_train, y_train, epochs=500, validation_data=(x_val, y_val))\n",
    "\n",
    "# Abrufen der besten Hyperparameter\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Die besten Hyperparameter sind:\n",
      "- Anzahl der Netzwerke: 160\n",
      "- Anzahl der Schichten: 10\n",
      "- Anzahl der Neuronen: 20\n",
      "- Delta: 4.156935364128902e-07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Die besten Hyperparameter sind:\n",
    "- Anzahl der Netzwerke: {best_hps.get('networks')}\n",
    "- Anzahl der Schichten: {best_hps.get('layers')}\n",
    "- Anzahl der Neuronen: {best_hps.get('units')}\n",
    "- Delta: {best_hps.get('learning_rate')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_dnn(model, train_data, test_data, epochs=75):\n",
    "    \"\"\"\n",
    "    Trains the model on the given data and evaluates its performance.\n",
    "    \"\"\"\n",
    "    model.fit(train_data, epochs=epochs, verbose=0)\n",
    "    mse, mae = model.evaluate(test_data, verbose=0)\n",
    "    return mse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:174: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\max-s\\Desktop\\Uni\\Master\\Masterthesis\\Code\\git\\overparametrized_dnn\\src\\my_dnn.py\", line 176, in train_step  *\n        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 269, in apply_gradients  **\n        self.apply(grads, trainable_variables)\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 334, in apply\n        variable.assign(variable.constraint(variable))\n    File \"c:\\Users\\max-s\\Desktop\\Uni\\Master\\Masterthesis\\Code\\git\\overparametrized_dnn\\src\\my_dnn.py\", line 65, in __call__\n        return self.apply_l1_projection(w)\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_type.py\", line 583, in canonicalize_to_monomorphic\n        _make_validated_mono_param(name, arg, poly_parameter.kind,\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_type.py\", line 522, in _make_validated_mono_param\n        mono_type = trace_type.from_value(value, type_context)\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\tensorflow\\core\\function\\trace_type\\trace_type_builder.py\", line 185, in from_value\n        ndarray = value.__array__()\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\backend\\common\\variables.py\", line 198, in __array__\n        return np.asarray(self.value.__array__(dtype))\n\n    NotImplementedError: numpy() is only available when eager execution is enabled.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 30\u001b[0m\n\u001b[0;32m     25\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m15\u001b[39m))\n\u001b[0;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     28\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     29\u001b[0m )\n\u001b[1;32m---> 30\u001b[0m mse, mae \u001b[38;5;241m=\u001b[39m train_and_evaluate_dnn(model, train_data, test_data, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n\u001b[0;32m     31\u001b[0m mses\u001b[38;5;241m.\u001b[39mappend(mse)\n\u001b[0;32m     32\u001b[0m maes\u001b[38;5;241m.\u001b[39mappend(mae)\n",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m, in \u001b[0;36mtrain_and_evaluate_dnn\u001b[1;34m(model, train_data, test_data, epochs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_and_evaluate_dnn\u001b[39m(model, train_data, test_data, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m75\u001b[39m):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    Trains the model on the given data and evaluates its performance.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(train_data, epochs\u001b[38;5;241m=\u001b[39mepochs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      6\u001b[0m     mse, mae \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_data, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mse, mae\n",
      "File \u001b[1;32mc:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileegyz1r8b.py:28\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     26\u001b[0m trainable_vars \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mtrainable_variables\n\u001b[0;32m     27\u001b[0m gradients \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tape)\u001b[38;5;241m.\u001b[39mgradient, (ag__\u001b[38;5;241m.\u001b[39mld(loss), ag__\u001b[38;5;241m.\u001b[39mld(trainable_vars)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m---> 28\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mapply_gradients, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mzip\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(gradients), ag__\u001b[38;5;241m.\u001b[39mld(trainable_vars)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     29\u001b[0m current_weights \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mconcat, ([ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mreshape, (ag__\u001b[38;5;241m.\u001b[39mld(w), [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]), \u001b[38;5;28;01mNone\u001b[39;00m, fscope) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mtrainable_variables[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]],), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), fscope)\n\u001b[0;32m     30\u001b[0m sub_nets_init_weights \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39msub_nets_init_weights\n",
      "File \u001b[1;32mc:\\Users\\max-s\\Desktop\\Uni\\Master\\Masterthesis\\Code\\git\\overparametrized_dnn\\src\\my_dnn.py:65\u001b[0m, in \u001b[0;36mL1Projection.__call__\u001b[1;34m(self, w)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, w):\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_l1_projection(w)\n",
      "File \u001b[1;32mc:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_type.py:583\u001b[0m, in \u001b[0;36mcanonicalize_to_monomorphic\u001b[1;34m(args, kwargs, default_values, capture_types, polymorphic_type)\u001b[0m\n\u001b[0;32m    577\u001b[0m       parameters\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    578\u001b[0m           _make_validated_mono_param(kwarg_name, arg[kwarg_name],\n\u001b[0;32m    579\u001b[0m                                      Parameter\u001b[38;5;241m.\u001b[39mKEYWORD_ONLY, type_context,\n\u001b[0;32m    580\u001b[0m                                      poly_parameter\u001b[38;5;241m.\u001b[39mtype_constraint))\n\u001b[0;32m    581\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    582\u001b[0m     parameters\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 583\u001b[0m         _make_validated_mono_param(name, arg, poly_parameter\u001b[38;5;241m.\u001b[39mkind,\n\u001b[0;32m    584\u001b[0m                                    type_context,\n\u001b[0;32m    585\u001b[0m                                    poly_parameter\u001b[38;5;241m.\u001b[39mtype_constraint))\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m FunctionType(parameters, capture_types), type_context\n",
      "File \u001b[1;32mc:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_type.py:522\u001b[0m, in \u001b[0;36m_make_validated_mono_param\u001b[1;34m(name, value, kind, type_context, poly_type)\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_validated_mono_param\u001b[39m(\n\u001b[0;32m    519\u001b[0m     name, value, kind, type_context, poly_type\n\u001b[0;32m    520\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Parameter:\n\u001b[0;32m    521\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Generates and validates a parameter for Monomorphic FunctionType.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 522\u001b[0m   mono_type \u001b[38;5;241m=\u001b[39m trace_type\u001b[38;5;241m.\u001b[39mfrom_value(value, type_context)\n\u001b[0;32m    524\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m poly_type \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mono_type\u001b[38;5;241m.\u001b[39mis_subtype_of(poly_type):\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` was expected to be of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpoly_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmono_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\tensorflow\\core\\function\\trace_type\\trace_type_builder.py:185\u001b[0m, in \u001b[0;36mfrom_value\u001b[1;34m(value, context)\u001b[0m\n\u001b[0;32m    178\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m default_types\u001b[38;5;241m.\u001b[39mAttrs\u001b[38;5;241m.\u001b[39mfrom_type_and_attributes(\n\u001b[0;32m    179\u001b[0m       \u001b[38;5;28mtype\u001b[39m(value),\n\u001b[0;32m    180\u001b[0m       \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m    181\u001b[0m           from_value(\u001b[38;5;28mgetattr\u001b[39m(value, a\u001b[38;5;241m.\u001b[39mname), context)\n\u001b[0;32m    182\u001b[0m           \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__attrs_attrs__))\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m util\u001b[38;5;241m.\u001b[39mis_np_ndarray(value):\n\u001b[1;32m--> 185\u001b[0m   ndarray \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39m__array__()\n\u001b[0;32m    186\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m default_types\u001b[38;5;241m.\u001b[39mTENSOR(ndarray\u001b[38;5;241m.\u001b[39mshape, ndarray\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, custom_nest_protocol\u001b[38;5;241m.\u001b[39mCustomNestProtocol):\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: in user code:\n\n    File \"c:\\Users\\max-s\\Desktop\\Uni\\Master\\Masterthesis\\Code\\git\\overparametrized_dnn\\src\\my_dnn.py\", line 176, in train_step  *\n        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 269, in apply_gradients  **\n        self.apply(grads, trainable_variables)\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 334, in apply\n        variable.assign(variable.constraint(variable))\n    File \"c:\\Users\\max-s\\Desktop\\Uni\\Master\\Masterthesis\\Code\\git\\overparametrized_dnn\\src\\my_dnn.py\", line 65, in __call__\n        return self.apply_l1_projection(w)\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_type.py\", line 583, in canonicalize_to_monomorphic\n        _make_validated_mono_param(name, arg, poly_parameter.kind,\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_type.py\", line 522, in _make_validated_mono_param\n        mono_type = trace_type.from_value(value, type_context)\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\tensorflow\\core\\function\\trace_type\\trace_type_builder.py\", line 185, in from_value\n        ndarray = value.__array__()\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\backend\\common\\variables.py\", line 198, in __array__\n        return np.asarray(self.value.__array__(dtype))\n\n    NotImplementedError: numpy() is only available when eager execution is enabled.\n"
     ]
    }
   ],
   "source": [
    "mses = []  # Initialize empty list to store MSEs\n",
    "maes = []  # Initialize empty list to store MAEs\n",
    "for _ in range(1):\n",
    "    x_train, y_train = get_data(\n",
    "        regression_func, x_dim=input_dim, num_samples=100, sigma=0.05\n",
    "    )\n",
    "    x_test, y_test = get_data(\n",
    "        regression_func, x_dim=input_dim, num_samples=10**5, sigma=0.05\n",
    "    )\n",
    "\n",
    "    # Preprocess data\n",
    "    train_data = preprocess(x_train, y_train, batch_size=100, training=True)\n",
    "    test_data = preprocess(x_test, y_test, batch_size=100, training=False)\n",
    "\n",
    "    model = create_dnn(\n",
    "        train_shape=x_train.shape,  # Beispielwerte\n",
    "        num_networks=160,\n",
    "        num_layers=10,\n",
    "        num_neurons=20,\n",
    "        beta=80,\n",
    "        gamma=80,\n",
    "        delta=1,\n",
    "    )\n",
    "\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=np.exp(-15))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"mean_squared_error\", metrics=[\"mean_squared_error\"]\n",
    "    )\n",
    "    mse, mae = train_and_evaluate_dnn(model, train_data, test_data, epochs=500)\n",
    "    mses.append(mse)\n",
    "    maes.append(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95123291015625]\n"
     ]
    }
   ],
   "source": [
    "print(mses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.0071 - mean_squared_error: 0.0071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.007052791304886341, 0.007052791304886341]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val, y_val = get_data(m1, x_dim=m1.expected_dim, num_samples=10**5)\n",
    "validation_data = preprocess(x_val, y_val, training=False)\n",
    "\n",
    "model.evaluate(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_norm_l1(model):\n",
    "    # Test if L1 projection of last layer worked\n",
    "    weights = tf.reshape(model.trainable_variables[-1], [-1])\n",
    "    norm = tf.norm(weights, ord=1)\n",
    "    print(f\"norm: {norm}, gamma: {model.gamma}\")\n",
    "\n",
    "\n",
    "def test_norm_l2(model):\n",
    "    # Test if L2 projection of inner weights worked\n",
    "    current_weights = tf.concat(\n",
    "        [tf.reshape(v, [-1]) for v in model.trainable_weights[:-1]], axis=0\n",
    "    )\n",
    "    sub_nets_init_weights = model.sub_nets_init_weights\n",
    "    diff = sub_nets_init_weights - current_weights\n",
    "    norm = tf.norm(diff)\n",
    "    print(f\"norm: {norm}, delta: {model.delta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm: 0.7622666954994202, gamma: 10\n",
      "norm: 0.0030101335141807795, delta: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_norm_l1(model)\n",
    "test_norm_l2(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py4ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
