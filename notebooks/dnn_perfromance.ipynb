{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\max-s\\Desktop\\Uni\\Master\\Masterthesis\\Code\\git\\overparametrized_dnn\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Working Directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from data.data_generator import get_data, preprocess\n",
    "from src.my_dnn import create_dnn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n",
      "1.4.7\n",
      "1.26.4\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "#print(tf.keras.__version__)\n",
    "print(kt.__version__)\n",
    "print(np.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_func(x):\n",
    "    return np.exp(np.linalg.norm(x, axis=1))\n",
    "\n",
    "input_dim = 7\n",
    "\n",
    "x, y = get_data(regression_func, x_dim=input_dim, num_samples=100, sigma=0.05)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "train_data = preprocess(x_train, y_train, batch_size=80, training=True)\n",
    "val_data = preprocess(x_val, y_val, batch_size=20, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.72715"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "403.629/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\max-s\\Desktop\\Uni\\Master\\Masterthesis\\Code\\git\\overparametrized_dnn\\src\\my_dnn.py\", line 148, in train_step\n        if tf.linalg.global_norm(vars_diff) > self.delta:\n\n    OperatorNotAllowedInGraphError: Using a symbolic `tf.Tensor` as a Python `bool` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 17\u001b[0m\n\u001b[0;32m     11\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m14\u001b[39m))\n\u001b[0;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     14\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     15\u001b[0m )\n\u001b[1;32m---> 17\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train_data, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39mval_data)\n",
      "File \u001b[1;32mc:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\autograph_util.py:52\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m     51\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mOperatorNotAllowedInGraphError\u001b[0m: in user code:\n\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\max-s\\Desktop\\Uni\\Master\\Masterthesis\\Code\\git\\overparametrized_dnn\\src\\my_dnn.py\", line 148, in train_step\n        if tf.linalg.global_norm(vars_diff) > self.delta:\n\n    OperatorNotAllowedInGraphError: Using a symbolic `tf.Tensor` as a Python `bool` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\n"
     ]
    }
   ],
   "source": [
    "model = create_dnn(\n",
    "        train_shape=x_train.shape,  # Beispielwerte\n",
    "        num_networks=100,\n",
    "        num_layers=10,\n",
    "        num_neurons=20,\n",
    "        beta=80,\n",
    "        gamma=80,\n",
    "        delta=1,\n",
    "    )\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=np.exp(-14))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer, loss=\"mean_squared_error\"\n",
    ")\n",
    "\n",
    "model.fit(train_data, epochs=10, validation_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    hp_units = hp.Int(\"units\", min_value=10, max_value=40, step=10)\n",
    "    hp_layers = hp.Int(\"layers\", min_value=5, max_value=20, step=5)\n",
    "    hp_nets = hp.Int(\"networks\", min_value=80, max_value=6 * 80, step=80)\n",
    "    hp_beta = hp.Float('beta', min_value=20, max_value=80)\n",
    "    hp_gamma = hp.Float('gamma', min_value=30, max_value=80)\n",
    "    hp_learning_rate = hp.Float(\n",
    "        \"learning_rate\", min_value=np.exp(-16), max_value=np.exp(-14), sampling=\"log\"\n",
    "    )\n",
    "\n",
    "    # Hier nutzen Sie Ihre angepasste `create_dnn` Funktion mit den hp-Argumenten\n",
    "    model = create_dnn(\n",
    "        train_shape=x_train.shape,  # Beispielwerte\n",
    "        num_networks=hp_nets,\n",
    "        num_layers=hp_layers,\n",
    "        num_neurons=hp_units,\n",
    "        beta=hp_beta,\n",
    "        gamma=hp_gamma,\n",
    "        delta=1,\n",
    "    )\n",
    "\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=hp_learning_rate)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"mean_squared_error\", metrics=[\"mean_squared_error\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    model_builder,\n",
    "    objective='val_loss',\n",
    "    max_trials=20,\n",
    "    executions_per_trial=2,\n",
    "    directory='my_dir',\n",
    "    project_name='rs_tuning'\n",
    ")\n",
    "\n",
    "# Starten des Tuning-Prozesses\n",
    "tuner.search(x_train, y_train, epochs=250, validation_data=(x_val, y_val))\n",
    "\n",
    "# Abrufen der besten Hyperparameter\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Die besten Hyperparameter sind:\n",
      "- Anzahl der Netzwerke: 160\n",
      "- Anzahl der Schichten: 10\n",
      "- Anzahl der Neuronen: 20\n",
      "- Delta: 4.156935364128902e-07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Die besten Hyperparameter sind:\n",
    "- Anzahl der Netzwerke: {best_hps.get('networks')}\n",
    "- Anzahl der Schichten: {best_hps.get('layers')}\n",
    "- Anzahl der Neuronen: {best_hps.get('units')}\n",
    "- Delta: {best_hps.get('learning_rate')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_dnn(model, train_data, test_data, epochs=75):\n",
    "    \"\"\"\n",
    "    Trains the model on the given data and evaluates its performance.\n",
    "    \"\"\"\n",
    "    model.fit(train_data, epochs=epochs, verbose=0)\n",
    "    mse, mae = model.evaluate(test_data, verbose=0)\n",
    "    return mse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:174: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\max-s\\Desktop\\Uni\\Master\\Masterthesis\\Code\\git\\overparametrized_dnn\\src\\my_dnn.py\", line 176, in train_step  *\n        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 269, in apply_gradients  **\n        self.apply(grads, trainable_variables)\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 334, in apply\n        variable.assign(variable.constraint(variable))\n    File \"c:\\Users\\max-s\\Desktop\\Uni\\Master\\Masterthesis\\Code\\git\\overparametrized_dnn\\src\\my_dnn.py\", line 65, in __call__\n        return self.apply_l1_projection(w)\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_type.py\", line 583, in canonicalize_to_monomorphic\n        _make_validated_mono_param(name, arg, poly_parameter.kind,\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_type.py\", line 522, in _make_validated_mono_param\n        mono_type = trace_type.from_value(value, type_context)\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\tensorflow\\core\\function\\trace_type\\trace_type_builder.py\", line 185, in from_value\n        ndarray = value.__array__()\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\backend\\common\\variables.py\", line 198, in __array__\n        return np.asarray(self.value.__array__(dtype))\n\n    NotImplementedError: numpy() is only available when eager execution is enabled.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 30\u001b[0m\n\u001b[0;32m     25\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m15\u001b[39m))\n\u001b[0;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     28\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     29\u001b[0m )\n\u001b[1;32m---> 30\u001b[0m mse, mae \u001b[38;5;241m=\u001b[39m train_and_evaluate_dnn(model, train_data, test_data, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n\u001b[0;32m     31\u001b[0m mses\u001b[38;5;241m.\u001b[39mappend(mse)\n\u001b[0;32m     32\u001b[0m maes\u001b[38;5;241m.\u001b[39mappend(mae)\n",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m, in \u001b[0;36mtrain_and_evaluate_dnn\u001b[1;34m(model, train_data, test_data, epochs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_and_evaluate_dnn\u001b[39m(model, train_data, test_data, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m75\u001b[39m):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    Trains the model on the given data and evaluates its performance.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(train_data, epochs\u001b[38;5;241m=\u001b[39mepochs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      6\u001b[0m     mse, mae \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_data, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mse, mae\n",
      "File \u001b[1;32mc:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileegyz1r8b.py:28\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     26\u001b[0m trainable_vars \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mtrainable_variables\n\u001b[0;32m     27\u001b[0m gradients \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tape)\u001b[38;5;241m.\u001b[39mgradient, (ag__\u001b[38;5;241m.\u001b[39mld(loss), ag__\u001b[38;5;241m.\u001b[39mld(trainable_vars)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m---> 28\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mapply_gradients, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mzip\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(gradients), ag__\u001b[38;5;241m.\u001b[39mld(trainable_vars)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     29\u001b[0m current_weights \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mconcat, ([ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mreshape, (ag__\u001b[38;5;241m.\u001b[39mld(w), [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]), \u001b[38;5;28;01mNone\u001b[39;00m, fscope) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mtrainable_variables[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]],), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), fscope)\n\u001b[0;32m     30\u001b[0m sub_nets_init_weights \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39msub_nets_init_weights\n",
      "File \u001b[1;32mc:\\Users\\max-s\\Desktop\\Uni\\Master\\Masterthesis\\Code\\git\\overparametrized_dnn\\src\\my_dnn.py:65\u001b[0m, in \u001b[0;36mL1Projection.__call__\u001b[1;34m(self, w)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, w):\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_l1_projection(w)\n",
      "File \u001b[1;32mc:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_type.py:583\u001b[0m, in \u001b[0;36mcanonicalize_to_monomorphic\u001b[1;34m(args, kwargs, default_values, capture_types, polymorphic_type)\u001b[0m\n\u001b[0;32m    577\u001b[0m       parameters\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    578\u001b[0m           _make_validated_mono_param(kwarg_name, arg[kwarg_name],\n\u001b[0;32m    579\u001b[0m                                      Parameter\u001b[38;5;241m.\u001b[39mKEYWORD_ONLY, type_context,\n\u001b[0;32m    580\u001b[0m                                      poly_parameter\u001b[38;5;241m.\u001b[39mtype_constraint))\n\u001b[0;32m    581\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    582\u001b[0m     parameters\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 583\u001b[0m         _make_validated_mono_param(name, arg, poly_parameter\u001b[38;5;241m.\u001b[39mkind,\n\u001b[0;32m    584\u001b[0m                                    type_context,\n\u001b[0;32m    585\u001b[0m                                    poly_parameter\u001b[38;5;241m.\u001b[39mtype_constraint))\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m FunctionType(parameters, capture_types), type_context\n",
      "File \u001b[1;32mc:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_type.py:522\u001b[0m, in \u001b[0;36m_make_validated_mono_param\u001b[1;34m(name, value, kind, type_context, poly_type)\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_validated_mono_param\u001b[39m(\n\u001b[0;32m    519\u001b[0m     name, value, kind, type_context, poly_type\n\u001b[0;32m    520\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Parameter:\n\u001b[0;32m    521\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Generates and validates a parameter for Monomorphic FunctionType.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 522\u001b[0m   mono_type \u001b[38;5;241m=\u001b[39m trace_type\u001b[38;5;241m.\u001b[39mfrom_value(value, type_context)\n\u001b[0;32m    524\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m poly_type \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mono_type\u001b[38;5;241m.\u001b[39mis_subtype_of(poly_type):\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` was expected to be of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpoly_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmono_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\tensorflow\\core\\function\\trace_type\\trace_type_builder.py:185\u001b[0m, in \u001b[0;36mfrom_value\u001b[1;34m(value, context)\u001b[0m\n\u001b[0;32m    178\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m default_types\u001b[38;5;241m.\u001b[39mAttrs\u001b[38;5;241m.\u001b[39mfrom_type_and_attributes(\n\u001b[0;32m    179\u001b[0m       \u001b[38;5;28mtype\u001b[39m(value),\n\u001b[0;32m    180\u001b[0m       \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m    181\u001b[0m           from_value(\u001b[38;5;28mgetattr\u001b[39m(value, a\u001b[38;5;241m.\u001b[39mname), context)\n\u001b[0;32m    182\u001b[0m           \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__attrs_attrs__))\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m util\u001b[38;5;241m.\u001b[39mis_np_ndarray(value):\n\u001b[1;32m--> 185\u001b[0m   ndarray \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39m__array__()\n\u001b[0;32m    186\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m default_types\u001b[38;5;241m.\u001b[39mTENSOR(ndarray\u001b[38;5;241m.\u001b[39mshape, ndarray\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, custom_nest_protocol\u001b[38;5;241m.\u001b[39mCustomNestProtocol):\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: in user code:\n\n    File \"c:\\Users\\max-s\\Desktop\\Uni\\Master\\Masterthesis\\Code\\git\\overparametrized_dnn\\src\\my_dnn.py\", line 176, in train_step  *\n        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 269, in apply_gradients  **\n        self.apply(grads, trainable_variables)\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py\", line 334, in apply\n        variable.assign(variable.constraint(variable))\n    File \"c:\\Users\\max-s\\Desktop\\Uni\\Master\\Masterthesis\\Code\\git\\overparametrized_dnn\\src\\my_dnn.py\", line 65, in __call__\n        return self.apply_l1_projection(w)\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_type.py\", line 583, in canonicalize_to_monomorphic\n        _make_validated_mono_param(name, arg, poly_parameter.kind,\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\tensorflow\\core\\function\\polymorphism\\function_type.py\", line 522, in _make_validated_mono_param\n        mono_type = trace_type.from_value(value, type_context)\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\tensorflow\\core\\function\\trace_type\\trace_type_builder.py\", line 185, in from_value\n        ndarray = value.__array__()\n    File \"c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\backend\\common\\variables.py\", line 198, in __array__\n        return np.asarray(self.value.__array__(dtype))\n\n    NotImplementedError: numpy() is only available when eager execution is enabled.\n"
     ]
    }
   ],
   "source": [
    "mses = []  # Initialize empty list to store MSEs\n",
    "maes = []  # Initialize empty list to store MAEs\n",
    "for _ in range(1):\n",
    "    x_train, y_train = get_data(\n",
    "        regression_func, x_dim=input_dim, num_samples=100, sigma=0.05\n",
    "    )\n",
    "    x_test, y_test = get_data(\n",
    "        regression_func, x_dim=input_dim, num_samples=10**5, sigma=0.05\n",
    "    )\n",
    "\n",
    "    # Preprocess data\n",
    "    train_data = preprocess(x_train, y_train, batch_size=100, training=True)\n",
    "    test_data = preprocess(x_test, y_test, batch_size=100, training=False)\n",
    "\n",
    "    model = create_dnn(\n",
    "        train_shape=x_train.shape,  # Beispielwerte\n",
    "        num_networks=160,\n",
    "        num_layers=10,\n",
    "        num_neurons=20,\n",
    "        beta=80,\n",
    "        gamma=80,\n",
    "        delta=1,\n",
    "    )\n",
    "\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=np.exp(-15))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"mean_squared_error\", metrics=[\"mean_squared_error\"]\n",
    "    )\n",
    "    mse, mae = train_and_evaluate_dnn(model, train_data, test_data, epochs=500)\n",
    "    mses.append(mse)\n",
    "    maes.append(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95123291015625]\n"
     ]
    }
   ],
   "source": [
    "print(mses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = create_dnn(\n",
    "        train_shape=x_train.shape,  # Beispielwerte\n",
    "        num_networks=10,\n",
    "        num_layers=10,\n",
    "        num_neurons=20,\n",
    "        beta=80,\n",
    "        gamma=80,\n",
    "        delta=1,\n",
    "    )\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=np.exp(-14))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer, loss=\"mean_squared_error\"\n",
    ")\n",
    "\n",
    "model.fit(train_data, epochs=10, validation_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\max-s\\anaconda3\\envs\\py4ds\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "1/1 [==============================] - 183s 183s/step - loss: 24.3104 - val_loss: 18.9069\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 21.3919 - val_loss: 16.4487\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 18.8508 - val_loss: 14.3193\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 16.6383 - val_loss: 12.4755\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 14.7118 - val_loss: 10.8795\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 13.0343 - val_loss: 9.4987\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 11.5736 - val_loss: 8.3048\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 10.3016 - val_loss: 7.2730\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 9.1940 - val_loss: 6.3818\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 8.2294 - val_loss: 5.6125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2793d4923d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.0071 - mean_squared_error: 0.0071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.007052791304886341, 0.007052791304886341]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val, y_val = get_data(m1, x_dim=m1.expected_dim, num_samples=10**5)\n",
    "validation_data = preprocess(x_val, y_val, training=False)\n",
    "\n",
    "model.evaluate(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_l1_projection(self, w):\n",
    "    if tf.norm(w, ord=1) <= self:\n",
    "        return w\n",
    "    # Apply L1-projection on weight vector w\n",
    "    abs_w = tf.abs(w)\n",
    "\n",
    "    # Compute cumulative sum of the sorted absolute weights\n",
    "    u = tf.sort(abs_w, direction=\"DESCENDING\", axis=0)\n",
    "    svp = tf.cumsum(u, axis=0) - self\n",
    "    print(u.numpy())\n",
    "    print(svp)\n",
    "\n",
    "    # Find the position where the condition is violated for the first time\n",
    "    ratio = tf.math.divide(svp, tf.constant(tf.range(1, tf.size(u) + 1, dtype=tf.float32), shape=tf.shape(u)))\n",
    "    print(ratio.numpy())\n",
    "\n",
    "    # Compute the threshold value\n",
    "    theta = tf.reduce_max(tf.maximum(ratio, 0.0), axis=0)\n",
    "    print(theta.numpy())\n",
    "\n",
    "    return tf.math.sign(w) * tf.maximum(abs_w - theta, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.ones(shape=(11, 1)), dtype=tf.float32)\n",
    "apply_l1_projection(7.0, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_norm_l1(model):\n",
    "    # Test if L1 projection of last layer worked\n",
    "    weights = tf.reshape(model.trainable_variables[-1], [-1])\n",
    "    norm = tf.norm(weights, ord=1)\n",
    "    print(f\"norm: {norm}, gamma: 80\")\n",
    "\n",
    "\n",
    "def test_norm_l2(model):\n",
    "    # Test if L2 projection of inner weights worked\n",
    "    current_weights = tf.concat(\n",
    "        [tf.reshape(v, [-1]) for v in model.trainable_weights[:-1]], axis=0\n",
    "    )\n",
    "    sub_nets_init_weights = tf.concat(\n",
    "        [tf.reshape(v, [-1]) for v in model.init_vars], axis=0\n",
    "    )\n",
    "    diff = sub_nets_init_weights - current_weights\n",
    "    norm = tf.norm(diff)\n",
    "    print(f\"norm: {norm}, delta: 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm: 0.06658446043729782, gamma: 80\n",
      "norm: 8.979407721199095e-05, delta: 1\n"
     ]
    }
   ],
   "source": [
    "test_norm_l1(model)\n",
    "test_norm_l2(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def calculate_iqr(data):\n",
    "\n",
    "    q75, q25 = np.percentile(data, [75, 25])\n",
    "    return q75 - q25\n",
    "\n",
    "\n",
    "def iqr_median(my_func, x_dim=1, num_samples=10**5, num_repetitions=100):\n",
    "    \"\"\"Function to calculate the IQR for a given function\"\"\"\n",
    "\n",
    "    iqr_values = []\n",
    "    rng = np.random.default_rng(42)\n",
    "\n",
    "    for _ in range(num_repetitions):\n",
    "        x_samples = rng.random((num_samples, x_dim))\n",
    "        my_func_values = my_func(x_samples)\n",
    "        iqr_values.append(calculate_iqr(my_func_values))\n",
    "        print(\"-------------------------\")\n",
    "        print(x_samples)\n",
    "\n",
    "    return np.median(iqr_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "[[0.77395605 0.43887844 0.85859792 0.69736803 0.09417735 0.97562235\n",
      "  0.7611397 ]\n",
      " [0.78606431 0.12811363 0.45038594 0.37079802 0.92676499 0.64386512\n",
      "  0.82276161]\n",
      " [0.4434142  0.22723872 0.55458479 0.06381726 0.82763117 0.6316644\n",
      "  0.75808774]\n",
      " [0.35452597 0.97069802 0.89312112 0.7783835  0.19463871 0.466721\n",
      "  0.04380377]\n",
      " [0.15428949 0.68304895 0.74476216 0.96750973 0.32582536 0.37045971\n",
      "  0.46955581]\n",
      " [0.18947136 0.12992151 0.47570493 0.22690935 0.66981399 0.43715192\n",
      "  0.8326782 ]\n",
      " [0.7002651  0.31236664 0.8322598  0.80476436 0.38747838 0.2883281\n",
      "  0.6824955 ]\n",
      " [0.13975248 0.1999082  0.00736227 0.78692438 0.66485086 0.70516538\n",
      "  0.78072903]\n",
      " [0.45891578 0.5687412  0.139797   0.11453007 0.66840296 0.47109621\n",
      "  0.56523611]\n",
      " [0.76499886 0.63471832 0.5535794  0.55920716 0.3039501  0.03081783\n",
      "  0.43671739]]\n",
      "-------------------------\n",
      "[[0.21458467 0.40852864 0.85340307 0.23393949 0.05830274 0.28138389\n",
      "  0.29359376]\n",
      " [0.66191651 0.55703215 0.78389821 0.66431354 0.40638686 0.81402038\n",
      "  0.16697292]\n",
      " [0.02271207 0.09004786 0.72235935 0.46187723 0.16127178 0.50104478\n",
      "  0.1523121 ]\n",
      " [0.69632038 0.44615628 0.38102123 0.30151209 0.63028259 0.36181261\n",
      "  0.08764992]\n",
      " [0.1180059  0.96189766 0.90858069 0.69970713 0.26586996 0.96917638\n",
      "  0.7787509 ]\n",
      " [0.71689019 0.4493615  0.27224156 0.09639096 0.9026024  0.45577629\n",
      "  0.20236336]\n",
      " [0.30595662 0.57921957 0.17677278 0.85661428 0.75851953 0.71946296\n",
      "  0.43209304]\n",
      " [0.62730884 0.58409797 0.6498466  0.08444432 0.4158074  0.04161417\n",
      "  0.49399082]\n",
      " [0.32986121 0.14452419 0.10340297 0.58764457 0.17059297 0.92512012\n",
      "  0.58106114]\n",
      " [0.3468698  0.59091549 0.02280387 0.95855921 0.48230344 0.78273523\n",
      "  0.08273   ]]\n",
      "-------------------------\n",
      "[[0.48665833 0.49070699 0.93782645 0.57172805 0.4734894  0.26697566\n",
      "  0.331569  ]\n",
      " [0.5206724  0.43891146 0.02161208 0.82629192 0.89616077 0.14024909\n",
      "  0.55403614]\n",
      " [0.10857574 0.67224009 0.28123378 0.65942263 0.72699461 0.76864749\n",
      "  0.10774095]\n",
      " [0.91601185 0.23021399 0.03741256 0.55485247 0.37092228 0.82978974\n",
      "  0.80825147]\n",
      " [0.31713889 0.9528994  0.29091784 0.51505713 0.25596509 0.93604357\n",
      "  0.16460782]\n",
      " [0.04491062 0.43509706 0.99237556 0.89167727 0.74860802 0.89079249\n",
      "  0.89344664]\n",
      " [0.51885836 0.31592905 0.77201243 0.66166126 0.37365773 0.09446667\n",
      "  0.74678961]\n",
      " [0.26246052 0.93681315 0.24097058 0.12275793 0.83111267 0.15328432\n",
      "  0.17926831]\n",
      " [0.59938279 0.87456204 0.19643467 0.31032367 0.77740484 0.97182643\n",
      "  0.50074119]\n",
      " [0.1438975  0.01393629 0.22965603 0.13182222 0.67765867 0.1218325\n",
      "  0.50632993]]\n",
      "-------------------------\n",
      "[[0.69426244 0.58111661 0.19977565 0.80412453 0.71540713 0.738984\n",
      "  0.13105775]\n",
      " [0.1237538  0.92756255 0.39757819 0.30094869 0.48858405 0.66286421\n",
      "  0.95562326]\n",
      " [0.28644623 0.92480843 0.02485949 0.55519804 0.63397511 0.1058974\n",
      "  0.1403396 ]\n",
      " [0.41911432 0.96623191 0.59604255 0.93302322 0.80436092 0.4673816\n",
      "  0.78476345]\n",
      " [0.01783678 0.109144   0.82942861 0.79681709 0.23264074 0.53076959\n",
      "  0.60601582]\n",
      " [0.86773895 0.60310716 0.41257157 0.37418404 0.42588209 0.65193103\n",
      "  0.86749063]\n",
      " [0.45389688 0.24783956 0.23666236 0.74601428 0.81656876 0.10527808\n",
      "  0.06655886]\n",
      " [0.59443366 0.14617324 0.82466419 0.31033467 0.14387193 0.92097047\n",
      "  0.16553172]\n",
      " [0.28472008 0.1536134  0.11549006 0.02114802 0.05539541 0.17464147\n",
      "  0.05338193]\n",
      " [0.59114382 0.68071453 0.39363046 0.3179911  0.50452624 0.87500494\n",
      "  0.85113163]]\n",
      "-------------------------\n",
      "[[0.04347506 0.18149841 0.23674487 0.24938758 0.57123265 0.41626243\n",
      "  0.04925412]\n",
      " [0.37361414 0.52375295 0.1016719  0.83345855 0.05196187 0.92484187\n",
      "  0.09911314]\n",
      " [0.84357495 0.90265314 0.97957068 0.80202588 0.77947754 0.64248328\n",
      "  0.77899635]\n",
      " [0.13455221 0.53606804 0.51422287 0.85757214 0.46279937 0.3850895\n",
      "  0.63956327]\n",
      " [0.26646332 0.13976841 0.47787727 0.41688937 0.23256994 0.36751181\n",
      "  0.36639245]\n",
      " [0.32749556 0.37946408 0.68574335 0.29687647 0.94885793 0.91634802\n",
      "  0.48091043]\n",
      " [0.32836121 0.53543479 0.84856049 0.65258734 0.80439183 0.53272228\n",
      "  0.63291763]\n",
      " [0.28815561 0.73489316 0.20240459 0.69479813 0.86071907 0.13210284\n",
      "  0.61437974]\n",
      " [0.09509575 0.72571563 0.08449322 0.93593982 0.13740793 0.95888025\n",
      "  0.80088418]\n",
      " [0.593682   0.7826241  0.79511484 0.94602706 0.25338335 0.5900759\n",
      "  0.0950492 ]]\n",
      "-------------------------\n",
      "[[0.6161657  0.1712913  0.56495061 0.57243051 0.46598515 0.52263178\n",
      "  0.76392339]\n",
      " [0.79924472 0.49215322 0.59959344 0.93123624 0.11973359 0.11710357\n",
      "  0.08770901]\n",
      " [0.65786329 0.4186083  0.77432142 0.67123141 0.33363776 0.89836655\n",
      "  0.76253215]\n",
      " [0.27053494 0.36419202 0.31443998 0.15761165 0.14778337 0.93612746\n",
      "  0.43790404]\n",
      " [0.38331982 0.72968571 0.55299307 0.93613999 0.78030149 0.47936956\n",
      "  0.37635947]\n",
      " [0.98663154 0.71776024 0.95119466 0.11847858 0.85053368 0.63707388\n",
      "  0.12192168]\n",
      " [0.588258   0.68609637 0.01230269 0.45431796 0.82539951 0.29535903\n",
      "  0.45854808]\n",
      " [0.44231413 0.30192739 0.9184419  0.78129404 0.11058841 0.99703466\n",
      "  0.87920002]\n",
      " [0.28390844 0.83689658 0.10641953 0.99910473 0.66568474 0.65012502\n",
      "  0.09044073]\n",
      " [0.8970334  0.0289995  0.24082806 0.14302188 0.77676794 0.19820423\n",
      "  0.91063823]]\n",
      "-------------------------\n",
      "[[0.65626904 0.03616271 0.00542983 0.05165792 0.60592518 0.80148181\n",
      "  0.23855282]\n",
      " [0.84940884 0.05723194 0.80096385 0.92779543 0.7721084  0.69812078\n",
      "  0.83798022]\n",
      " [0.0401513  0.20178211 0.12492368 0.50453099 0.74518813 0.63001184\n",
      "  0.8511311 ]\n",
      " [0.15521299 0.73462109 0.19304149 0.27075875 0.7099047  0.98020478\n",
      "  0.61154361]\n",
      " [0.05450031 0.61630897 0.04235055 0.88414571 0.70957829 0.17312785\n",
      "  0.09172101]\n",
      " [0.18353323 0.98002718 0.45856064 0.78408095 0.63640834 0.57241315\n",
      "  0.14513025]\n",
      " [0.94602445 0.30134263 0.57801722 0.69977594 0.64923316 0.94059441\n",
      "  0.14843899]\n",
      " [0.50835274 0.40403439 0.47416873 0.11921753 0.13409461 0.27807555\n",
      "  0.3047046 ]\n",
      " [0.42790321 0.61098755 0.63462912 0.4118109  0.40878311 0.21762853\n",
      "  0.58830625]\n",
      " [0.31704091 0.03605983 0.41840004 0.47413268 0.22559287 0.57245793\n",
      "  0.5657719 ]]\n",
      "-------------------------\n",
      "[[0.70200218 0.64794848 0.65243306 0.31621415 0.78743222 0.54914438\n",
      "  0.4314182 ]\n",
      " [0.62601248 0.36065733 0.51273924 0.73670569 0.88640289 0.9210572\n",
      "  0.50363293]\n",
      " [0.52027511 0.79987041 0.31445069 0.83738236 0.49414165 0.11585672\n",
      "  0.07205915]\n",
      " [0.84199321 0.05556792 0.28061144 0.33413004 0.17299445 0.31389337\n",
      "  0.74269257]\n",
      " [0.01468284 0.82717342 0.85654802 0.37226157 0.1536129  0.60084041\n",
      "  0.11967256]\n",
      " [0.36491936 0.95842918 0.99546447 0.77210489 0.31096151 0.68766505\n",
      "  0.70540637]\n",
      " [0.3878417  0.64088863 0.01072764 0.20905766 0.5250883  0.1637513\n",
      "  0.16590687]\n",
      " [0.83630429 0.989133   0.55596943 0.83906973 0.99032166 0.14159589\n",
      "  0.44824561]\n",
      " [0.39257272 0.08004928 0.75533017 0.43377903 0.46932693 0.15067297\n",
      "  0.18092665]\n",
      " [0.90710362 0.04464909 0.23285228 0.29205933 0.49019754 0.58644517\n",
      "  0.49328998]]\n",
      "-------------------------\n",
      "[[0.08411533 0.24366745 0.84358838 0.6375887  0.64914905 0.67020326\n",
      "  0.76290302]\n",
      " [0.05810848 0.36660838 0.53952744 0.33845648 0.84447887 0.48257251\n",
      "  0.76862759]\n",
      " [0.85201552 0.50479148 0.90955224 0.58712394 0.8502743  0.3405908\n",
      "  0.49881696]\n",
      " [0.53141104 0.10497972 0.39855251 0.91733767 0.63083224 0.17750658\n",
      "  0.33885564]\n",
      " [0.19160301 0.02482313 0.92746046 0.44820733 0.30753507 0.59847719\n",
      "  0.00731446]\n",
      " [0.27802211 0.70303347 0.63376977 0.98180595 0.62035771 0.47750587\n",
      "  0.76143256]\n",
      " [0.90332787 0.72069595 0.96321122 0.78200517 0.86680144 0.11410407\n",
      "  0.7324135 ]\n",
      " [0.4400887  0.5531038  0.65410241 0.96981512 0.98457808 0.28822825\n",
      "  0.7337535 ]\n",
      " [0.74998354 0.34649286 0.12386977 0.04094696 0.77734313 0.48969974\n",
      "  0.98554017]\n",
      " [0.46497346 0.97791698 0.411576   0.79368215 0.08481927 0.55546171\n",
      "  0.80205979]]\n",
      "-------------------------\n",
      "[[0.92470167 0.82258309 0.03697073 0.37270234 0.04869847 0.10928229\n",
      "  0.67530563]\n",
      " [0.7132582  0.77372068 0.86545655 0.73943147 0.80087159 0.04896371\n",
      "  0.23453515]\n",
      " [0.62189777 0.8581253  0.00450012 0.51462934 0.6772874  0.02960729\n",
      "  0.40135556]\n",
      " [0.89563488 0.67161281 0.23765836 0.85278113 0.34803142 0.85334467\n",
      "  0.29894365]\n",
      " [0.59032025 0.39694007 0.27482505 0.88655756 0.18759368 0.08481159\n",
      "  0.34192694]\n",
      " [0.71763915 0.80743161 0.99874337 0.29636206 0.40794195 0.13682128\n",
      "  0.57487193]\n",
      " [0.99758004 0.70088101 0.59521284 0.39236909 0.91529876 0.4969166\n",
      "  0.13436691]\n",
      " [0.36537846 0.06716667 0.20197904 0.01766878 0.45327992 0.63454026\n",
      "  0.34329246]\n",
      " [0.42038177 0.95920927 0.75196312 0.54085664 0.28454088 0.8969968\n",
      "  0.23509712]\n",
      " [0.32534273 0.90906481 0.52954206 0.74231795 0.59074479 0.65343921\n",
      "  0.29938329]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.4402881839413224"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iqr_median(regression_func, x_dim=7, num_samples=10, num_repetitions=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py4ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
