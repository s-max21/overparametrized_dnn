{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\max-s\\Desktop\\Uni\\Master\\Masterthesis\\Code\\git\\overparametrized_dnn\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Working Directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data_generator import get_data, preprocess\n",
    "from src.my_dnn import create_dnn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras_tuner as kt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_func(x):\n",
    "    return np.exp(np.linalg.norm(x, axis=1))\n",
    "\n",
    "input_dim = 7\n",
    "\n",
    "x, y = get_data(regression_func, x_dim=input_dim, num_samples=100, sigma=0.05)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "train_data = preprocess(x_train, y_train, batch_size=20, training=True)\n",
    "val_data = preprocess(x_val, y_val, batch_size=20, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    hp_units = hp.Int(\"units\", min_value=10, max_value=20, step=10)\n",
    "    hp_layers = hp.Int(\"layers\", min_value=10, max_value=20, step=10)\n",
    "    hp_nets = hp.Int(\"networks\", min_value=80, max_value=2 * 80, step=80)\n",
    "    # hp_beta = hp.Float('beta', min_value=20, max_value=80)\n",
    "    # hp_gamma = hp.Float('gamma', min_value=30, max_value=80)\n",
    "    hp_learning_rate = hp.Float(\n",
    "        \"learning_rate\", min_value=np.exp(-16), max_value=np.exp(-14), sampling=\"log\"\n",
    "    )\n",
    "\n",
    "    # Hier nutzen Sie Ihre angepasste `create_dnn` Funktion mit den hp-Argumenten\n",
    "    model = create_dnn(\n",
    "        train_shape=x_train.shape,  # Beispielwerte\n",
    "        num_networks=hp_nets,\n",
    "        num_layers=hp_layers,\n",
    "        num_neurons=hp_units,\n",
    "        beta=80,\n",
    "        gamma=80,\n",
    "        delta=1,\n",
    "    )\n",
    "\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=hp_learning_rate)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"mean_squared_error\", metrics=[\"mean_squared_error\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    model_builder,\n",
    "    objective='val_loss',\n",
    "    max_trials=20,\n",
    "    executions_per_trial=2,\n",
    "    directory='my_dir',\n",
    "    project_name='keras_tuner_demo'\n",
    ")\n",
    "\n",
    "# Starten des Tuning-Prozesses\n",
    "# Hinweis: Ersetzen Sie `x_train`, `y_train`, `x_val`, `y_val` durch Ihre Daten.\n",
    "tuner.search(x_train, y_train, epochs=100, validation_data=(x_val, y_val))\n",
    "\n",
    "# Abrufen der besten Hyperparameter\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Die besten Hyperparameter sind:\n",
      "- Anzahl der Netzwerke: 160\n",
      "- Anzahl der Schichten: 10\n",
      "- Anzahl der Neuronen: 20\n",
      "- Delta: 4.156935364128902e-07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Die besten Hyperparameter sind:\n",
    "- Anzahl der Netzwerke: {best_hps.get('networks')}\n",
    "- Anzahl der Schichten: {best_hps.get('layers')}\n",
    "- Anzahl der Neuronen: {best_hps.get('units')}\n",
    "- Delta: {best_hps.get('learning_rate')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_dnn(model, train_data, test_data, epochs=75):\n",
    "    \"\"\"\n",
    "    Trains the model on the given data and evaluates its performance.\n",
    "    \"\"\"\n",
    "    model.fit(train_data, epochs=epochs, verbose=0)\n",
    "    mse, mae = model.evaluate(test_data, verbose=0)\n",
    "    return mse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mses = []  # Initialize empty list to store MSEs\n",
    "maes = []  # Initialize empty list to store MAEs\n",
    "for _ in range(1):\n",
    "    x_train, y_train = get_data(\n",
    "        regression_func, x_dim=input_dim, num_samples=100, sigma=0.05\n",
    "    )\n",
    "    x_test, y_test = get_data(\n",
    "        regression_func, x_dim=input_dim, num_samples=10**5, sigma=0.05\n",
    "    )\n",
    "\n",
    "    # Preprocess data\n",
    "    train_data = preprocess(x_train, y_train, batch_size=100, training=True)\n",
    "    test_data = preprocess(x_test, y_test, batch_size=100, training=False)\n",
    "\n",
    "    model = create_dnn(\n",
    "        train_shape=x_train.shape,  # Beispielwerte\n",
    "        num_networks=160,\n",
    "        num_layers=10,\n",
    "        num_neurons=20,\n",
    "        beta=80,\n",
    "        gamma=80,\n",
    "        delta=1,\n",
    "    )\n",
    "\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=np.exp(-15))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"mean_squared_error\", metrics=[\"mean_squared_error\"]\n",
    "    )\n",
    "    mse, mae = train_and_evaluate_dnn(model, train_data, test_data, epochs=1000)\n",
    "    mses.append(mse)\n",
    "    maes.append(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95123291015625]\n"
     ]
    }
   ],
   "source": [
    "print(mses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.0071 - mean_squared_error: 0.0071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.007052791304886341, 0.007052791304886341]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val, y_val = get_data(m1, x_dim=m1.expected_dim, num_samples=10**5)\n",
    "validation_data = preprocess(x_val, y_val, training=False)\n",
    "\n",
    "model.evaluate(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_norm_l1(model):\n",
    "    # Test if L1 projection of last layer worked\n",
    "    weights = tf.reshape(model.trainable_variables[-1], [-1])\n",
    "    norm = tf.norm(weights, ord=1)\n",
    "    print(\"norm: {}, gamma: {}\".format(norm, model.gamma))\n",
    "\n",
    "\n",
    "def test_norm_l2(model):\n",
    "    # Test if L2 projection of inner weights worked\n",
    "    current_weights = tf.concat(\n",
    "        [tf.reshape(v, [-1]) for v in model.trainable_weights[:-1]], axis=0\n",
    "    )\n",
    "    sub_nets_init_weights = model.sub_nets_init_weights\n",
    "    diff = sub_nets_init_weights - current_weights\n",
    "    norm = tf.norm(diff)\n",
    "    print(\"norm: {}, delta: {}\".format(norm, model.delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm: 0.7622666954994202, gamma: 10\n",
      "norm: 0.0030101335141807795, delta: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_norm_l1(model)\n",
    "test_norm_l2(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py4ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
